2024-09-13 19:05:56,951 [trainer.py] => Time Str >>> 0913-19-05-56-486
2024-09-13 19:05:56,967 [trainer.py] => prefix: benchmark
2024-09-13 19:05:56,967 [trainer.py] => dataset: cifar100
2024-09-13 19:05:56,967 [trainer.py] => memory_size: 2000
2024-09-13 19:05:56,968 [trainer.py] => memory_per_class: 20
2024-09-13 19:05:56,968 [trainer.py] => fixed_memory: False
2024-09-13 19:05:56,968 [trainer.py] => shuffle: True
2024-09-13 19:05:56,968 [trainer.py] => init_cls: 10
2024-09-13 19:05:56,968 [trainer.py] => increment: 10
2024-09-13 19:05:56,968 [trainer.py] => model_name: podnet
2024-09-13 19:05:56,968 [trainer.py] => convnet_type: resnet32
2024-09-13 19:05:56,968 [trainer.py] => device: [device(type='cuda', index=0)]
2024-09-13 19:05:56,968 [trainer.py] => seed: 1993
2024-09-13 19:05:56,969 [trainer.py] => debug: False
2024-09-13 19:05:56,969 [trainer.py] => skip: False
2024-09-13 19:05:56,969 [trainer.py] => config: ./exps/podnet.json
2024-09-13 19:05:56,969 [trainer.py] => time_str: 0913-19-05-56-486
2024-09-13 19:05:56,969 [trainer.py] => exp_name: 0913-19-05-56-486_cifar100_resnet32_1993_B0_Inc10
2024-09-13 19:05:56,969 [trainer.py] => logfilename: logs/benchmark/cifar100/podnet/0913-19-05-56-486_cifar100_resnet32_1993_B0_Inc10
2024-09-13 19:05:56,969 [trainer.py] => csv_name: cifar100_1993_resnet32_B0_Inc10
2024-09-13 19:06:02,816 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-09-13 19:06:03,034 [trainer.py] => Start time:1726254363.0341609
2024-09-13 19:06:03,034 [trainer.py] => All params: 463504
2024-09-13 19:06:03,035 [trainer.py] => Trainable params: 463504
2024-09-13 19:06:03,035 [podnet.py] => Learning on 0-10
2024-09-13 19:06:03,050 [podnet.py] => Adaptive factor: 0
2024-09-13 19:06:10,738 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 2.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 15.56, Test_acc 21.30
2024-09-13 19:06:16,973 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 2.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 26.38, Test_acc 20.90
2024-09-13 19:06:20,990 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 1.93, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 32.46, Test_acc 30.10
2024-09-13 19:06:25,023 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 1.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 39.42, Test_acc 36.60
2024-09-13 19:06:29,903 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 1.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 47.44, Test_acc 46.20
2024-09-13 19:06:34,416 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 1.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 47.22, Test_acc 34.50
2024-09-13 19:06:38,420 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 1.40, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 54.26, Test_acc 50.60
2024-09-13 19:06:42,922 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 1.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 54.12, Test_acc 50.10
2024-09-13 19:06:49,126 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 1.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 58.86, Test_acc 55.20
2024-09-13 19:06:53,060 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 1.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 58.82, Test_acc 56.10
2024-09-13 19:06:57,031 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 1.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 62.68, Test_acc 49.10
2024-09-13 19:07:01,974 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 1.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 63.28, Test_acc 52.20
2024-09-13 19:07:08,330 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 1.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 67.36, Test_acc 59.50
2024-09-13 19:07:12,357 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 1.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 66.08, Test_acc 60.00
2024-09-13 19:07:16,531 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 0.95, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 70.48, Test_acc 60.80
2024-09-13 19:07:21,665 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 0.92, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.68, Test_acc 63.30
2024-09-13 19:07:25,935 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 0.97, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 69.30, Test_acc 64.60
2024-09-13 19:07:29,870 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 0.86, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.40, Test_acc 64.00
2024-09-13 19:07:34,348 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.52, Test_acc 67.60
2024-09-13 19:07:40,376 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 0.87, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.72, Test_acc 66.50
2024-09-13 19:07:44,355 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 0.79, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.30, Test_acc 70.00
2024-09-13 19:07:48,279 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 0.80, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.22, Test_acc 63.80
2024-09-13 19:07:53,055 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 0.76, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.68, Test_acc 75.00
2024-09-13 19:07:59,394 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 0.77, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.32, Test_acc 70.10
2024-09-13 19:08:03,337 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 0.83, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.24, Test_acc 75.00
2024-09-13 19:08:07,280 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.04, Test_acc 66.60
2024-09-13 19:08:12,254 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 0.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.04, Test_acc 76.20
2024-09-13 19:08:17,066 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 0.64, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.12, Test_acc 76.30
2024-09-13 19:08:21,051 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 0.66, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.64, Test_acc 74.10
2024-09-13 19:08:25,408 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.28, Test_acc 78.30
2024-09-13 19:08:31,450 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 0.61, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 81.20, Test_acc 80.80
2024-09-13 19:08:35,454 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.48, Test_acc 69.20
2024-09-13 19:08:39,449 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.82, Test_acc 74.30
2024-09-13 19:08:44,337 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 0.58, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.48, Test_acc 70.00
2024-09-13 19:08:50,788 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.54, Test_acc 72.00
2024-09-13 19:08:56,277 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.88, Test_acc 80.40
2024-09-13 19:09:00,253 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.16, Test_acc 71.10
2024-09-13 19:09:05,817 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 0.69, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.04, Test_acc 77.80
2024-09-13 19:09:09,762 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 0.65, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.72, Test_acc 57.80
2024-09-13 19:09:13,727 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.06, Test_acc 75.80
2024-09-13 19:09:18,719 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 0.59, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.96, Test_acc 77.00
2024-09-13 19:09:24,964 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.66, Test_acc 78.20
2024-09-13 19:09:28,965 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.28, Test_acc 80.60
2024-09-13 19:09:32,914 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.40, Test_acc 80.30
2024-09-13 19:09:37,672 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.84, Test_acc 80.30
2024-09-13 19:09:44,010 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.37, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.28, Test_acc 82.50
2024-09-13 19:09:48,170 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.46, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.74, Test_acc 80.70
2024-09-13 19:09:52,182 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.26, Test_acc 81.70
2024-09-13 19:09:57,125 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.56, Test_acc 77.80
2024-09-13 19:10:01,727 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.04, Test_acc 80.20
2024-09-13 19:10:05,670 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.60, Test_acc 81.40
2024-09-13 19:10:09,953 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.98, Test_acc 79.80
2024-09-13 19:10:15,746 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.50, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.10, Test_acc 82.30
2024-09-13 19:10:19,827 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.80, Test_acc 77.80
2024-09-13 19:10:23,742 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.68, Test_acc 70.40
2024-09-13 19:10:28,557 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.08, Test_acc 82.50
2024-09-13 19:10:34,537 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.00, Test_acc 77.90
2024-09-13 19:10:38,501 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.36, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.72, Test_acc 82.60
2024-09-13 19:10:42,538 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.90, Test_acc 84.30
2024-09-13 19:10:47,724 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.08, Test_acc 84.90
2024-09-13 19:10:52,182 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.98, Test_acc 86.00
2024-09-13 19:10:56,084 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.10, Test_acc 73.40
2024-09-13 19:11:00,390 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.44, Test_acc 83.20
2024-09-13 19:11:06,428 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.00, Test_acc 81.50
2024-09-13 19:11:10,451 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.60, Test_acc 84.50
2024-09-13 19:11:14,420 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.46, Test_acc 79.90
2024-09-13 19:11:19,415 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.92, Test_acc 85.40
2024-09-13 19:11:25,304 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.78, Test_acc 86.20
2024-09-13 19:11:29,268 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.06, Test_acc 79.00
2024-09-13 19:11:33,517 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.42, Test_acc 82.60
2024-09-13 19:11:39,370 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.48, Test_acc 82.70
2024-09-13 19:11:43,544 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.12, Test_acc 84.50
2024-09-13 19:11:47,761 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.70, Test_acc 85.80
2024-09-13 19:11:52,658 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.96, Test_acc 84.60
2024-09-13 19:11:58,924 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.70, Test_acc 83.10
2024-09-13 19:12:02,868 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.29, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.00, Test_acc 83.50
2024-09-13 19:12:06,825 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.46, Test_acc 85.10
2024-09-13 19:12:11,615 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.82, Test_acc 84.80
2024-09-13 19:12:18,000 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.34, Test_acc 85.60
2024-09-13 19:12:21,972 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.60, Test_acc 84.70
2024-09-13 19:12:26,893 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.44, Test_acc 87.00
2024-09-13 19:12:33,005 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.40, Test_acc 86.60
2024-09-13 19:12:37,014 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.92, Test_acc 83.60
2024-09-13 19:12:41,018 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.98, Test_acc 86.20
2024-09-13 19:12:45,703 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.60, Test_acc 84.60
2024-09-13 19:12:52,001 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.34, Test_acc 81.00
2024-09-13 19:12:55,962 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.40, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.30, Test_acc 80.70
2024-09-13 19:12:59,926 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.94, Test_acc 85.10
2024-09-13 19:13:04,812 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.66, Test_acc 86.30
2024-09-13 19:13:10,600 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.92, Test_acc 84.00
2024-09-13 19:13:14,588 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.16, Test_acc 87.60
2024-09-13 19:13:18,492 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.82, Test_acc 87.70
2024-09-13 19:13:23,954 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.84, Test_acc 86.70
2024-09-13 19:13:27,876 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.22, Test_acc 88.30
2024-09-13 19:13:31,823 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.54, Test_acc 84.20
2024-09-13 19:13:36,590 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.32, Test_acc 86.40
2024-09-13 19:13:42,735 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.90, Test_acc 85.20
2024-09-13 19:13:46,701 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.12, Test_acc 83.10
2024-09-13 19:13:50,795 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.54, Test_acc 87.90
2024-09-13 19:13:55,723 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 88.80
2024-09-13 19:14:01,878 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.78, Test_acc 87.80
2024-09-13 19:14:05,827 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.28, Test_acc 84.00
2024-09-13 19:14:09,811 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.64, Test_acc 88.40
2024-09-13 19:14:15,183 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.66, Test_acc 88.80
2024-09-13 19:14:19,433 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.26, Test_acc 82.20
2024-09-13 19:14:23,529 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.16, Test_acc 87.50
2024-09-13 19:14:28,218 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 86.70
2024-09-13 19:14:34,492 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.20, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.08, Test_acc 87.80
2024-09-13 19:14:38,580 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.66, Test_acc 86.00
2024-09-13 19:14:42,566 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.34, Test_acc 88.90
2024-09-13 19:14:47,464 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.74, Test_acc 86.00
2024-09-13 19:14:53,871 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.58, Test_acc 88.40
2024-09-13 19:14:57,925 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.88, Test_acc 86.00
2024-09-13 19:15:02,029 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.76, Test_acc 86.40
2024-09-13 19:15:07,008 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.82, Test_acc 88.10
2024-09-13 19:15:13,190 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.46, Test_acc 88.70
2024-09-13 19:15:17,285 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.06, Test_acc 89.50
2024-09-13 19:15:21,307 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.00, Test_acc 88.10
2024-09-13 19:15:26,595 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.56, Test_acc 88.60
2024-09-13 19:15:30,890 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.78, Test_acc 88.90
2024-09-13 19:15:34,967 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.26, Test_acc 89.90
2024-09-13 19:15:39,786 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.40, Test_acc 89.80
2024-09-13 19:15:46,172 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 89.50
2024-09-13 19:15:50,259 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.36, Test_acc 89.80
2024-09-13 19:15:54,419 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 90.20
2024-09-13 19:15:59,695 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.90, Test_acc 90.20
2024-09-13 19:16:05,845 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 90.10
2024-09-13 19:16:09,853 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.28, Test_acc 90.00
2024-09-13 19:16:14,904 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.86, Test_acc 90.10
2024-09-13 19:16:19,084 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 89.80
2024-09-13 19:16:23,253 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 89.80
2024-09-13 19:16:27,937 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 89.80
2024-09-13 19:16:33,985 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.94, Test_acc 89.40
2024-09-13 19:16:38,110 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.92, Test_acc 89.90
2024-09-13 19:16:42,145 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 89.90
2024-09-13 19:16:47,234 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.00, Test_acc 89.70
2024-09-13 19:16:51,842 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 90.40
2024-09-13 19:16:55,866 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 90.50
2024-09-13 19:17:00,219 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 89.60
2024-09-13 19:17:06,383 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 89.00
2024-09-13 19:17:10,464 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 89.80
2024-09-13 19:17:14,464 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 89.70
2024-09-13 19:17:19,491 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.26, Test_acc 89.60
2024-09-13 19:17:24,296 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.30, Test_acc 88.90
2024-09-13 19:17:28,292 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 89.60
2024-09-13 19:17:32,593 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.10
2024-09-13 19:17:38,614 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.48, Test_acc 89.30
2024-09-13 19:17:42,686 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.44, Test_acc 89.50
2024-09-13 19:17:46,684 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 90.00
2024-09-13 19:17:51,782 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 89.60
2024-09-13 19:17:56,312 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 89.50
2024-09-13 19:18:00,324 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 89.70
2024-09-13 19:18:05,030 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.20
2024-09-13 19:18:11,386 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 90.10
2024-09-13 19:18:15,450 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.20
2024-09-13 19:18:19,539 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.50, Test_acc 90.10
2024-09-13 19:18:24,631 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 89.40
2024-09-13 19:18:30,880 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 90.00
2024-09-13 19:18:34,877 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.30
2024-09-13 19:18:39,144 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 90.30
2024-09-13 19:18:39,145 [base.py] => Reducing exemplars...(200 per classes)
2024-09-13 19:18:39,146 [base.py] => Constructing exemplars...(200 per classes)
2024-09-13 19:18:49,290 [podnet.py] => Exemplar size: 2000
2024-09-13 19:18:49,291 [trainer.py] => CNN: {'total': 90.3, '00-09': 90.3, 'old': 0, 'new': 90.3}
2024-09-13 19:18:49,291 [trainer.py] => NME: {'total': 90.3, '00-09': 90.3, 'old': 0, 'new': 90.3}
2024-09-13 19:18:49,291 [trainer.py] => CNN top1 curve: [90.3]
2024-09-13 19:18:49,292 [trainer.py] => CNN top5 curve: [99.3]
2024-09-13 19:18:49,292 [trainer.py] => NME top1 curve: [90.3]
2024-09-13 19:18:49,292 [trainer.py] => NME top5 curve: [99.3]

2024-09-13 19:18:49,293 [trainer.py] => All params: 469905
2024-09-13 19:18:49,293 [trainer.py] => Trainable params: 469905
2024-09-13 19:18:49,294 [podnet.py] => Learning on 10-20
2024-09-13 19:18:49,345 [podnet.py] => Adaptive factor: 1.4142135623730951
2024-09-13 19:18:56,312 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 1.95, Spatial_loss 1.74, Flat_loss 0.09, Train_acc 44.63, Test_acc 55.35
2024-09-13 19:19:05,288 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 1.48, Spatial_loss 1.60, Flat_loss 0.07, Train_acc 53.06, Test_acc 52.95
2024-09-13 19:19:11,493 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 1.38, Spatial_loss 1.60, Flat_loss 0.08, Train_acc 57.11, Test_acc 54.30
2024-09-13 19:19:19,016 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 1.31, Spatial_loss 1.59, Flat_loss 0.08, Train_acc 58.94, Test_acc 56.50
2024-09-13 19:19:25,176 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 1.25, Spatial_loss 1.55, Flat_loss 0.08, Train_acc 60.80, Test_acc 57.95
2024-09-13 19:19:33,764 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 1.19, Spatial_loss 1.50, Flat_loss 0.08, Train_acc 63.03, Test_acc 56.45
2024-09-13 19:19:42,826 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 1.17, Spatial_loss 1.54, Flat_loss 0.09, Train_acc 64.47, Test_acc 59.70
2024-09-13 19:19:48,947 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 1.10, Spatial_loss 1.45, Flat_loss 0.08, Train_acc 66.33, Test_acc 55.25
2024-09-13 19:19:56,617 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 1.07, Spatial_loss 1.49, Flat_loss 0.09, Train_acc 67.09, Test_acc 60.70
2024-09-13 19:20:02,692 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 1.07, Spatial_loss 1.53, Flat_loss 0.09, Train_acc 66.87, Test_acc 62.45
2024-09-13 19:20:09,741 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 1.02, Spatial_loss 1.46, Flat_loss 0.09, Train_acc 68.89, Test_acc 56.55
2024-09-13 19:20:16,011 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.98, Spatial_loss 1.46, Flat_loss 0.09, Train_acc 70.23, Test_acc 56.90
2024-09-13 19:20:22,627 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.97, Spatial_loss 1.47, Flat_loss 0.09, Train_acc 70.87, Test_acc 58.65
2024-09-13 19:20:31,774 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.94, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 71.41, Test_acc 59.35
2024-09-13 19:20:37,848 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.93, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 71.86, Test_acc 53.60
2024-09-13 19:20:45,239 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.89, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 72.44, Test_acc 60.15
2024-09-13 19:20:51,403 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.88, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 73.03, Test_acc 61.95
2024-09-13 19:20:58,718 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.87, Spatial_loss 1.44, Flat_loss 0.10, Train_acc 73.89, Test_acc 61.60
2024-09-13 19:21:05,169 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.86, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 74.00, Test_acc 59.15
2024-09-13 19:21:11,752 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.84, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 74.84, Test_acc 65.30
2024-09-13 19:21:20,554 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.82, Spatial_loss 1.44, Flat_loss 0.10, Train_acc 75.71, Test_acc 59.25
2024-09-13 19:21:26,732 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.83, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 75.06, Test_acc 64.15
2024-09-13 19:21:34,134 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.78, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 76.69, Test_acc 56.05
2024-09-13 19:21:40,268 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.77, Spatial_loss 1.44, Flat_loss 0.10, Train_acc 76.21, Test_acc 62.85
2024-09-13 19:21:47,465 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.80, Spatial_loss 1.45, Flat_loss 0.10, Train_acc 75.66, Test_acc 60.20
2024-09-13 19:21:53,934 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.76, Spatial_loss 1.48, Flat_loss 0.11, Train_acc 77.66, Test_acc 62.15
2024-09-13 19:22:00,793 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.74, Spatial_loss 1.43, Flat_loss 0.10, Train_acc 77.77, Test_acc 61.15
2024-09-13 19:22:09,692 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.75, Spatial_loss 1.43, Flat_loss 0.10, Train_acc 77.11, Test_acc 65.65
2024-09-13 19:22:15,898 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.72, Spatial_loss 1.44, Flat_loss 0.11, Train_acc 78.29, Test_acc 58.90
2024-09-13 19:22:23,702 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.72, Spatial_loss 1.44, Flat_loss 0.11, Train_acc 79.46, Test_acc 60.25
2024-09-13 19:22:30,002 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.70, Spatial_loss 1.45, Flat_loss 0.11, Train_acc 79.17, Test_acc 65.55
2024-09-13 19:22:37,374 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.69, Spatial_loss 1.42, Flat_loss 0.10, Train_acc 79.20, Test_acc 61.65
2024-09-13 19:22:43,790 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.70, Spatial_loss 1.45, Flat_loss 0.11, Train_acc 79.19, Test_acc 61.05
2024-09-13 19:22:50,700 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.69, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 79.36, Test_acc 63.90
2024-09-13 19:23:00,699 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.64, Spatial_loss 1.37, Flat_loss 0.10, Train_acc 81.70, Test_acc 66.00
2024-09-13 19:23:06,740 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.64, Spatial_loss 1.41, Flat_loss 0.11, Train_acc 81.59, Test_acc 60.60
2024-09-13 19:23:14,126 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.66, Spatial_loss 1.45, Flat_loss 0.11, Train_acc 80.36, Test_acc 62.50
2024-09-13 19:23:20,232 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.65, Spatial_loss 1.41, Flat_loss 0.11, Train_acc 81.57, Test_acc 65.30
2024-09-13 19:23:27,129 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.63, Spatial_loss 1.39, Flat_loss 0.11, Train_acc 81.91, Test_acc 65.60
2024-09-13 19:23:36,097 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.62, Spatial_loss 1.41, Flat_loss 0.11, Train_acc 81.86, Test_acc 61.80
2024-09-13 19:23:42,192 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.61, Spatial_loss 1.40, Flat_loss 0.11, Train_acc 82.44, Test_acc 64.55
2024-09-13 19:23:49,689 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.61, Spatial_loss 1.41, Flat_loss 0.11, Train_acc 81.83, Test_acc 57.55
2024-09-13 19:23:55,818 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.60, Spatial_loss 1.41, Flat_loss 0.11, Train_acc 82.47, Test_acc 63.50
2024-09-13 19:24:03,110 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.59, Spatial_loss 1.40, Flat_loss 0.11, Train_acc 82.71, Test_acc 65.40
2024-09-13 19:24:09,411 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.60, Spatial_loss 1.43, Flat_loss 0.11, Train_acc 82.44, Test_acc 66.95
2024-09-13 19:24:16,185 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.58, Spatial_loss 1.42, Flat_loss 0.11, Train_acc 82.89, Test_acc 63.75
2024-09-13 19:24:25,048 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.55, Spatial_loss 1.37, Flat_loss 0.11, Train_acc 83.89, Test_acc 66.25
2024-09-13 19:24:30,968 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.56, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 83.81, Test_acc 63.95
2024-09-13 19:24:38,147 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.55, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 84.06, Test_acc 64.25
2024-09-13 19:24:44,196 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.53, Spatial_loss 1.37, Flat_loss 0.11, Train_acc 84.46, Test_acc 66.10
2024-09-13 19:24:51,102 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.52, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 85.04, Test_acc 64.75
2024-09-13 19:24:57,879 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.54, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 84.50, Test_acc 62.90
2024-09-13 19:25:04,542 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.51, Spatial_loss 1.37, Flat_loss 0.11, Train_acc 85.73, Test_acc 66.45
2024-09-13 19:25:13,666 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.53, Spatial_loss 1.39, Flat_loss 0.11, Train_acc 84.90, Test_acc 63.25
2024-09-13 19:25:19,760 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.52, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 84.84, Test_acc 65.85
2024-09-13 19:25:27,117 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.50, Spatial_loss 1.38, Flat_loss 0.11, Train_acc 85.94, Test_acc 66.90
2024-09-13 19:25:33,348 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.51, Spatial_loss 1.37, Flat_loss 0.11, Train_acc 85.50, Test_acc 61.20
2024-09-13 19:25:40,855 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.50, Spatial_loss 1.34, Flat_loss 0.11, Train_acc 85.99, Test_acc 58.70
2024-09-13 19:25:47,082 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.48, Spatial_loss 1.34, Flat_loss 0.11, Train_acc 86.43, Test_acc 64.20
2024-09-13 19:25:53,886 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.48, Spatial_loss 1.36, Flat_loss 0.11, Train_acc 86.47, Test_acc 62.90
2024-09-13 19:26:02,652 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.49, Spatial_loss 1.39, Flat_loss 0.11, Train_acc 85.93, Test_acc 63.40
2024-09-13 19:26:08,710 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.46, Spatial_loss 1.34, Flat_loss 0.11, Train_acc 87.26, Test_acc 66.90
2024-09-13 19:26:16,130 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.43, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 88.04, Test_acc 66.00
2024-09-13 19:26:22,365 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.43, Spatial_loss 1.29, Flat_loss 0.11, Train_acc 88.07, Test_acc 64.90
2024-09-13 19:26:32,166 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.43, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 88.03, Test_acc 64.65
2024-09-13 19:26:38,537 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.46, Spatial_loss 1.32, Flat_loss 0.11, Train_acc 87.17, Test_acc 65.60
2024-09-13 19:26:45,254 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.44, Spatial_loss 1.33, Flat_loss 0.11, Train_acc 88.01, Test_acc 66.80
2024-09-13 19:26:54,224 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.43, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 87.67, Test_acc 65.50
2024-09-13 19:27:00,373 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.42, Spatial_loss 1.31, Flat_loss 0.11, Train_acc 87.93, Test_acc 62.50
2024-09-13 19:27:08,054 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.42, Spatial_loss 1.28, Flat_loss 0.11, Train_acc 88.53, Test_acc 68.60
2024-09-13 19:27:14,070 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.39, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 89.40, Test_acc 67.90
2024-09-13 19:27:21,091 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.38, Spatial_loss 1.27, Flat_loss 0.11, Train_acc 89.34, Test_acc 64.25
2024-09-13 19:27:27,329 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.40, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 89.26, Test_acc 67.75
2024-09-13 19:27:33,908 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.39, Spatial_loss 1.29, Flat_loss 0.11, Train_acc 89.31, Test_acc 63.85
2024-09-13 19:27:42,806 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.40, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 88.86, Test_acc 64.95
2024-09-13 19:27:48,803 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.38, Spatial_loss 1.27, Flat_loss 0.11, Train_acc 89.67, Test_acc 67.00
2024-09-13 19:27:56,355 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 90.27, Test_acc 64.45
2024-09-13 19:28:02,537 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.36, Spatial_loss 1.26, Flat_loss 0.11, Train_acc 89.86, Test_acc 67.05
2024-09-13 19:28:09,674 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.37, Spatial_loss 1.25, Flat_loss 0.11, Train_acc 89.64, Test_acc 68.15
2024-09-13 19:28:18,319 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.36, Spatial_loss 1.27, Flat_loss 0.11, Train_acc 90.37, Test_acc 64.10
2024-09-13 19:28:24,476 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.35, Spatial_loss 1.23, Flat_loss 0.11, Train_acc 90.00, Test_acc 68.85
2024-09-13 19:28:32,232 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.33, Spatial_loss 1.22, Flat_loss 0.11, Train_acc 91.20, Test_acc 67.75
2024-09-13 19:28:38,379 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.11, Train_acc 91.10, Test_acc 67.35
2024-09-13 19:28:45,545 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.11, Train_acc 91.20, Test_acc 67.55
2024-09-13 19:28:51,803 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.34, Spatial_loss 1.19, Flat_loss 0.11, Train_acc 90.59, Test_acc 65.00
2024-09-13 19:28:58,666 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.33, Spatial_loss 1.21, Flat_loss 0.11, Train_acc 91.19, Test_acc 68.75
2024-09-13 19:29:07,496 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.31, Spatial_loss 1.19, Flat_loss 0.11, Train_acc 91.76, Test_acc 66.85
2024-09-13 19:29:13,568 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.22, Flat_loss 0.11, Train_acc 91.31, Test_acc 66.00
2024-09-13 19:29:20,925 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.33, Spatial_loss 1.20, Flat_loss 0.11, Train_acc 91.34, Test_acc 69.25
2024-09-13 19:29:27,024 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.30, Spatial_loss 1.20, Flat_loss 0.11, Train_acc 92.40, Test_acc 69.95
2024-09-13 19:29:34,037 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.29, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 92.67, Test_acc 66.90
2024-09-13 19:29:40,605 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.28, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 92.74, Test_acc 67.85
2024-09-13 19:29:47,410 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.27, Spatial_loss 1.14, Flat_loss 0.11, Train_acc 93.07, Test_acc 60.40
2024-09-13 19:29:57,258 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.29, Spatial_loss 1.17, Flat_loss 0.11, Train_acc 92.39, Test_acc 67.05
2024-09-13 19:30:03,339 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.28, Spatial_loss 1.15, Flat_loss 0.11, Train_acc 92.84, Test_acc 68.05
2024-09-13 19:30:10,913 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.27, Spatial_loss 1.12, Flat_loss 0.10, Train_acc 93.14, Test_acc 69.80
2024-09-13 19:30:17,086 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.25, Spatial_loss 1.13, Flat_loss 0.11, Train_acc 93.63, Test_acc 69.30
2024-09-13 19:30:23,918 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.26, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 93.46, Test_acc 68.10
2024-09-13 19:30:32,408 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.26, Spatial_loss 1.10, Flat_loss 0.10, Train_acc 93.59, Test_acc 68.45
2024-09-13 19:30:38,589 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.23, Spatial_loss 1.09, Flat_loss 0.10, Train_acc 94.49, Test_acc 67.10
2024-09-13 19:30:46,527 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.24, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 94.00, Test_acc 68.20
2024-09-13 19:30:52,560 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.25, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 93.83, Test_acc 68.40
2024-09-13 19:30:59,704 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.23, Spatial_loss 1.08, Flat_loss 0.10, Train_acc 94.36, Test_acc 71.40
2024-09-13 19:31:06,133 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 94.51, Test_acc 69.15
2024-09-13 19:31:12,757 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 1.07, Flat_loss 0.10, Train_acc 94.54, Test_acc 70.50
2024-09-13 19:31:21,155 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.10, Train_acc 94.94, Test_acc 68.75
2024-09-13 19:31:27,200 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 94.73, Test_acc 68.35
2024-09-13 19:31:34,670 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.10, Train_acc 95.16, Test_acc 69.80
2024-09-13 19:31:40,894 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.22, Spatial_loss 1.04, Flat_loss 0.10, Train_acc 94.73, Test_acc 69.90
2024-09-13 19:31:48,077 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.21, Spatial_loss 1.02, Flat_loss 0.10, Train_acc 95.13, Test_acc 68.95
2024-09-13 19:31:54,299 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 95.51, Test_acc 71.85
2024-09-13 19:32:01,146 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.20, Spatial_loss 1.00, Flat_loss 0.10, Train_acc 95.67, Test_acc 72.40
2024-09-13 19:32:09,705 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 96.47, Test_acc 71.35
2024-09-13 19:32:15,693 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.18, Spatial_loss 0.96, Flat_loss 0.10, Train_acc 96.17, Test_acc 69.80
2024-09-13 19:32:23,035 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 96.20, Test_acc 71.30
2024-09-13 19:32:29,101 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.18, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 96.07, Test_acc 71.45
2024-09-13 19:32:36,024 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 0.96, Flat_loss 0.10, Train_acc 96.24, Test_acc 71.60
2024-09-13 19:32:42,903 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.18, Spatial_loss 0.96, Flat_loss 0.10, Train_acc 96.00, Test_acc 68.40
2024-09-13 19:32:49,457 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 96.71, Test_acc 70.80
2024-09-13 19:32:58,491 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 96.77, Test_acc 71.80
2024-09-13 19:33:04,714 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 96.56, Test_acc 70.85
2024-09-13 19:33:12,594 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.10, Train_acc 96.93, Test_acc 70.40
2024-09-13 19:33:21,487 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 96.59, Test_acc 71.35
2024-09-13 19:33:29,311 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 97.23, Test_acc 71.65
2024-09-13 19:33:35,369 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 97.43, Test_acc 71.50
2024-09-13 19:33:42,744 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.09, Train_acc 97.43, Test_acc 71.65
2024-09-13 19:33:49,070 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.09, Train_acc 97.37, Test_acc 72.00
2024-09-13 19:33:55,654 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 97.77, Test_acc 72.40
2024-09-13 19:34:04,438 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 97.63, Test_acc 71.70
2024-09-13 19:34:10,490 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 97.57, Test_acc 71.65
2024-09-13 19:34:17,916 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.09, Train_acc 97.70, Test_acc 72.55
2024-09-13 19:34:23,996 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.14, Spatial_loss 0.86, Flat_loss 0.09, Train_acc 97.64, Test_acc 71.35
2024-09-13 19:34:31,235 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 97.96, Test_acc 72.15
2024-09-13 19:34:37,636 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 97.74, Test_acc 73.30
2024-09-13 19:34:44,667 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 98.09, Test_acc 72.75
2024-09-13 19:34:53,427 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 97.93, Test_acc 72.00
2024-09-13 19:34:59,501 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 98.03, Test_acc 72.30
2024-09-13 19:35:07,071 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.83, Flat_loss 0.09, Train_acc 98.07, Test_acc 72.15
2024-09-13 19:35:13,212 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 97.89, Test_acc 72.00
2024-09-13 19:35:20,263 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.09, Train_acc 98.07, Test_acc 73.45
2024-09-13 19:35:26,568 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.09, Train_acc 98.37, Test_acc 73.20
2024-09-13 19:35:33,176 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 98.30, Test_acc 72.80
2024-09-13 19:35:42,229 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.13, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 97.89, Test_acc 73.15
2024-09-13 19:35:48,258 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 98.34, Test_acc 72.45
2024-09-13 19:35:55,499 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 98.43, Test_acc 72.95
2024-09-13 19:36:01,469 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.23, Test_acc 72.85
2024-09-13 19:36:08,409 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.41, Test_acc 72.60
2024-09-13 19:36:16,082 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.53, Test_acc 73.00
2024-09-13 19:36:24,408 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.31, Test_acc 73.05
2024-09-13 19:36:31,371 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.51, Test_acc 72.70
2024-09-13 19:36:41,503 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.16, Test_acc 72.50
2024-09-13 19:36:48,802 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.50, Test_acc 72.95
2024-09-13 19:36:58,235 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.44, Test_acc 73.30
2024-09-13 19:37:05,321 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.51, Test_acc 73.05
2024-09-13 19:37:14,670 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.09, Train_acc 98.57, Test_acc 72.90
2024-09-13 19:37:21,722 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.39, Test_acc 72.55
2024-09-13 19:37:31,751 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.70, Test_acc 73.10
2024-09-13 19:37:39,876 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 98.41, Test_acc 73.00
2024-09-13 19:37:51,215 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.12, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.31, Test_acc 72.70
2024-09-13 19:37:59,347 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 98.60, Test_acc 72.80
2024-09-13 19:37:59,348 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 19:37:59,348 [base.py] => Reducing exemplars...(200 per classes)
2024-09-13 19:38:13,973 [base.py] => Constructing exemplars...(200 per classes)
2024-09-13 19:38:44,567 [podnet.py] => The size of finetune dataset: 4000
2024-09-13 19:38:50,270 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.07, Train_acc 98.42, Test_acc 72.75
2024-09-13 19:38:54,311 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.11, Spatial_loss 0.76, Flat_loss 0.07, Train_acc 98.22, Test_acc 73.50
2024-09-13 19:38:58,250 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.07, Train_acc 98.35, Test_acc 72.85
2024-09-13 19:39:03,147 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.07, Train_acc 98.15, Test_acc 71.90
2024-09-13 19:39:07,728 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.07, Train_acc 98.32, Test_acc 72.70
2024-09-13 19:39:11,716 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.07, Train_acc 98.60, Test_acc 72.65
2024-09-13 19:39:16,348 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.07, Train_acc 98.48, Test_acc 72.95
2024-09-13 19:39:22,322 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.07, Train_acc 98.48, Test_acc 72.80
2024-09-13 19:39:26,383 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.07, Train_acc 98.40, Test_acc 73.20
2024-09-13 19:39:30,463 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.07, Train_acc 98.35, Test_acc 72.95
2024-09-13 19:39:35,601 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 98.35, Test_acc 72.85
2024-09-13 19:39:39,935 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.07, Train_acc 98.78, Test_acc 73.10
2024-09-13 19:39:43,947 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.75, Flat_loss 0.07, Train_acc 98.35, Test_acc 72.90
2024-09-13 19:39:48,759 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 98.98, Test_acc 72.95
2024-09-13 19:39:54,618 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 98.42, Test_acc 73.20
2024-09-13 19:39:58,799 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.07, Train_acc 98.72, Test_acc 73.05
2024-09-13 19:40:04,526 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.07, Train_acc 98.82, Test_acc 73.00
2024-09-13 19:40:09,977 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.09, Spatial_loss 0.72, Flat_loss 0.07, Train_acc 98.65, Test_acc 72.55
2024-09-13 19:40:13,980 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.09, Spatial_loss 0.74, Flat_loss 0.07, Train_acc 98.55, Test_acc 73.25
2024-09-13 19:40:18,067 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.73, Flat_loss 0.07, Train_acc 99.12, Test_acc 72.90
2024-09-13 19:40:18,069 [base.py] => Reducing exemplars...(100 per classes)
2024-09-13 19:40:21,004 [base.py] => Constructing exemplars...(100 per classes)
2024-09-13 19:40:30,007 [podnet.py] => Exemplar size: 2000
2024-09-13 19:40:30,007 [trainer.py] => CNN: {'total': 72.9, '00-09': 80.0, '10-19': 65.8, 'old': 80.0, 'new': 65.8}
2024-09-13 19:40:30,008 [trainer.py] => NME: {'total': 69.15, '00-09': 83.7, '10-19': 54.6, 'old': 83.7, 'new': 54.6}
2024-09-13 19:40:30,008 [trainer.py] => CNN top1 curve: [90.3, 72.9]
2024-09-13 19:40:30,008 [trainer.py] => CNN top5 curve: [99.3, 91.95]
2024-09-13 19:40:30,008 [trainer.py] => NME top1 curve: [90.3, 69.15]
2024-09-13 19:40:30,008 [trainer.py] => NME top5 curve: [99.3, 91.35]

2024-09-13 19:40:30,009 [trainer.py] => All params: 476305
2024-09-13 19:40:30,009 [trainer.py] => Trainable params: 476305
2024-09-13 19:40:30,010 [podnet.py] => Learning on 20-30
2024-09-13 19:40:30,062 [podnet.py] => Adaptive factor: 1.7320508075688772
2024-09-13 19:40:37,664 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 2.25, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 47.81, Test_acc 44.13
2024-09-13 19:40:44,082 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 1.32, Spatial_loss 1.85, Flat_loss 0.10, Train_acc 62.39, Test_acc 48.60
2024-09-13 19:40:51,783 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 1.18, Spatial_loss 1.81, Flat_loss 0.10, Train_acc 65.84, Test_acc 49.10
2024-09-13 19:40:58,444 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 1.08, Spatial_loss 1.82, Flat_loss 0.10, Train_acc 68.71, Test_acc 47.77
2024-09-13 19:41:05,880 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 1.04, Spatial_loss 1.75, Flat_loss 0.09, Train_acc 70.54, Test_acc 49.37
2024-09-13 19:41:12,649 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 0.97, Spatial_loss 1.79, Flat_loss 0.10, Train_acc 72.03, Test_acc 50.97
2024-09-13 19:41:20,173 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 0.95, Spatial_loss 1.75, Flat_loss 0.10, Train_acc 73.43, Test_acc 50.00
2024-09-13 19:41:26,821 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 0.90, Spatial_loss 1.75, Flat_loss 0.10, Train_acc 73.91, Test_acc 52.47
2024-09-13 19:41:34,198 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.87, Spatial_loss 1.72, Flat_loss 0.10, Train_acc 75.91, Test_acc 52.17
2024-09-13 19:41:40,802 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.84, Spatial_loss 1.71, Flat_loss 0.10, Train_acc 75.77, Test_acc 56.00
2024-09-13 19:41:47,956 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.82, Spatial_loss 1.67, Flat_loss 0.10, Train_acc 77.13, Test_acc 55.77
2024-09-13 19:41:56,799 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.78, Spatial_loss 1.69, Flat_loss 0.10, Train_acc 78.21, Test_acc 55.03
2024-09-13 19:42:03,142 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.77, Spatial_loss 1.64, Flat_loss 0.10, Train_acc 78.39, Test_acc 43.03
2024-09-13 19:42:11,142 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.80, Spatial_loss 1.74, Flat_loss 0.10, Train_acc 76.96, Test_acc 55.87
2024-09-13 19:42:17,409 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.74, Spatial_loss 1.66, Flat_loss 0.10, Train_acc 78.97, Test_acc 53.47
2024-09-13 19:42:25,247 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.72, Spatial_loss 1.65, Flat_loss 0.10, Train_acc 80.01, Test_acc 52.23
2024-09-13 19:42:31,586 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.72, Spatial_loss 1.68, Flat_loss 0.10, Train_acc 79.74, Test_acc 51.03
2024-09-13 19:42:39,114 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.71, Spatial_loss 1.66, Flat_loss 0.10, Train_acc 80.24, Test_acc 52.80
2024-09-13 19:42:45,568 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.71, Spatial_loss 1.63, Flat_loss 0.10, Train_acc 80.40, Test_acc 55.43
2024-09-13 19:42:53,001 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.67, Spatial_loss 1.63, Flat_loss 0.10, Train_acc 80.77, Test_acc 54.83
2024-09-13 19:42:59,862 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.67, Spatial_loss 1.63, Flat_loss 0.10, Train_acc 81.09, Test_acc 54.97
2024-09-13 19:43:06,822 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.65, Spatial_loss 1.61, Flat_loss 0.10, Train_acc 82.09, Test_acc 54.80
2024-09-13 19:43:15,510 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.62, Spatial_loss 1.61, Flat_loss 0.10, Train_acc 82.59, Test_acc 51.83
2024-09-13 19:43:23,326 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.63, Spatial_loss 1.61, Flat_loss 0.10, Train_acc 82.64, Test_acc 57.20
2024-09-13 19:43:32,508 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.61, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 83.23, Test_acc 58.37
2024-09-13 19:43:38,738 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.60, Spatial_loss 1.61, Flat_loss 0.10, Train_acc 84.00, Test_acc 56.97
2024-09-13 19:43:46,460 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.60, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 83.13, Test_acc 56.70
2024-09-13 19:43:53,054 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.62, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 82.10, Test_acc 49.77
2024-09-13 19:44:00,749 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.59, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 83.54, Test_acc 57.07
2024-09-13 19:44:07,179 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.59, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 83.43, Test_acc 56.80
2024-09-13 19:44:14,535 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.56, Spatial_loss 1.53, Flat_loss 0.10, Train_acc 84.59, Test_acc 54.60
2024-09-13 19:44:21,358 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.57, Spatial_loss 1.56, Flat_loss 0.10, Train_acc 84.37, Test_acc 52.77
2024-09-13 19:44:28,568 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.57, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 84.90, Test_acc 56.27
2024-09-13 19:44:36,131 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.57, Spatial_loss 1.62, Flat_loss 0.11, Train_acc 83.94, Test_acc 54.63
2024-09-13 19:44:43,213 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.55, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 84.57, Test_acc 51.93
2024-09-13 19:44:52,661 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.55, Spatial_loss 1.56, Flat_loss 0.11, Train_acc 84.86, Test_acc 51.07
2024-09-13 19:45:00,283 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.52, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 85.86, Test_acc 54.47
2024-09-13 19:45:09,038 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.51, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 85.59, Test_acc 56.30
2024-09-13 19:45:15,310 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.50, Spatial_loss 1.52, Flat_loss 0.10, Train_acc 86.43, Test_acc 55.20
2024-09-13 19:45:22,990 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.52, Spatial_loss 1.54, Flat_loss 0.10, Train_acc 85.64, Test_acc 54.33
2024-09-13 19:45:29,466 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.50, Spatial_loss 1.53, Flat_loss 0.11, Train_acc 86.47, Test_acc 57.47
2024-09-13 19:45:36,614 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.52, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 85.74, Test_acc 53.60
2024-09-13 19:45:43,943 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.47, Spatial_loss 1.53, Flat_loss 0.10, Train_acc 87.41, Test_acc 56.27
2024-09-13 19:45:50,723 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.49, Spatial_loss 1.51, Flat_loss 0.11, Train_acc 86.77, Test_acc 55.70
2024-09-13 19:45:59,798 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.50, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 86.31, Test_acc 55.63
2024-09-13 19:46:06,054 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.47, Spatial_loss 1.53, Flat_loss 0.10, Train_acc 87.37, Test_acc 57.53
2024-09-13 19:46:13,527 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.48, Spatial_loss 1.55, Flat_loss 0.10, Train_acc 86.50, Test_acc 59.63
2024-09-13 19:46:19,758 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.49, Spatial_loss 1.54, Flat_loss 0.10, Train_acc 86.41, Test_acc 57.60
2024-09-13 19:46:27,725 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.47, Spatial_loss 1.54, Flat_loss 0.11, Train_acc 87.14, Test_acc 56.77
2024-09-13 19:46:34,147 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.44, Spatial_loss 1.51, Flat_loss 0.11, Train_acc 88.03, Test_acc 56.07
2024-09-13 19:46:41,549 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.44, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 88.17, Test_acc 56.27
2024-09-13 19:46:48,245 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.43, Spatial_loss 1.52, Flat_loss 0.11, Train_acc 88.44, Test_acc 54.87
2024-09-13 19:46:55,793 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.44, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 88.31, Test_acc 56.03
2024-09-13 19:47:02,494 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.44, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 87.91, Test_acc 55.17
2024-09-13 19:47:09,553 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.43, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 88.50, Test_acc 59.77
2024-09-13 19:47:17,975 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.42, Spatial_loss 1.51, Flat_loss 0.11, Train_acc 88.17, Test_acc 49.83
2024-09-13 19:47:24,415 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.43, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 88.51, Test_acc 56.13
2024-09-13 19:47:32,950 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.42, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 88.51, Test_acc 57.13
2024-09-13 19:47:39,303 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.42, Spatial_loss 1.45, Flat_loss 0.10, Train_acc 88.71, Test_acc 57.10
2024-09-13 19:47:46,935 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.41, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 88.84, Test_acc 58.63
2024-09-13 19:47:53,559 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.41, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 88.80, Test_acc 58.33
2024-09-13 19:48:01,511 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.40, Spatial_loss 1.40, Flat_loss 0.10, Train_acc 89.77, Test_acc 58.50
2024-09-13 19:48:07,938 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.36, Spatial_loss 1.42, Flat_loss 0.10, Train_acc 90.79, Test_acc 58.43
2024-09-13 19:48:15,794 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.38, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 90.31, Test_acc 58.40
2024-09-13 19:48:25,436 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.39, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 89.14, Test_acc 59.47
2024-09-13 19:48:33,173 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.41, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 88.44, Test_acc 58.30
2024-09-13 19:48:39,620 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.38, Spatial_loss 1.45, Flat_loss 0.10, Train_acc 90.00, Test_acc 48.57
2024-09-13 19:48:47,478 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.37, Spatial_loss 1.42, Flat_loss 0.10, Train_acc 90.31, Test_acc 59.27
2024-09-13 19:48:53,914 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.37, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 90.54, Test_acc 58.33
2024-09-13 19:49:01,631 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.36, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 90.74, Test_acc 56.30
2024-09-13 19:49:08,121 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.37, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 90.50, Test_acc 59.90
2024-09-13 19:49:15,394 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.36, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 90.46, Test_acc 55.70
2024-09-13 19:49:22,449 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.34, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 91.29, Test_acc 56.13
2024-09-13 19:49:29,700 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.35, Spatial_loss 1.40, Flat_loss 0.10, Train_acc 91.03, Test_acc 56.70
2024-09-13 19:49:38,802 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.35, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 90.83, Test_acc 57.53
2024-09-13 19:49:45,124 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.32, Spatial_loss 1.35, Flat_loss 0.10, Train_acc 92.11, Test_acc 58.90
2024-09-13 19:49:53,320 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.33, Spatial_loss 1.36, Flat_loss 0.10, Train_acc 92.01, Test_acc 60.17
2024-09-13 19:49:59,677 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.33, Spatial_loss 1.34, Flat_loss 0.10, Train_acc 91.83, Test_acc 57.73
2024-09-13 19:50:07,603 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.32, Spatial_loss 1.34, Flat_loss 0.10, Train_acc 91.79, Test_acc 59.43
2024-09-13 19:50:14,107 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.31, Spatial_loss 1.33, Flat_loss 0.10, Train_acc 92.53, Test_acc 57.90
2024-09-13 19:50:21,944 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.30, Spatial_loss 1.34, Flat_loss 0.10, Train_acc 92.74, Test_acc 59.33
2024-09-13 19:50:28,591 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.28, Spatial_loss 1.31, Flat_loss 0.10, Train_acc 93.57, Test_acc 59.83
2024-09-13 19:50:36,122 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.28, Spatial_loss 1.26, Flat_loss 0.10, Train_acc 93.26, Test_acc 56.83
2024-09-13 19:50:42,799 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.30, Spatial_loss 1.31, Flat_loss 0.10, Train_acc 92.64, Test_acc 58.67
2024-09-13 19:50:50,304 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.30, Spatial_loss 1.32, Flat_loss 0.10, Train_acc 92.63, Test_acc 59.83
2024-09-13 19:50:57,087 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.28, Spatial_loss 1.28, Flat_loss 0.10, Train_acc 93.33, Test_acc 58.77
2024-09-13 19:51:04,718 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.27, Spatial_loss 1.27, Flat_loss 0.10, Train_acc 93.76, Test_acc 56.37
2024-09-13 19:51:11,608 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.26, Spatial_loss 1.29, Flat_loss 0.10, Train_acc 93.86, Test_acc 58.97
2024-09-13 19:51:19,037 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.10, Train_acc 93.66, Test_acc 59.47
2024-09-13 19:51:25,852 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.10, Train_acc 94.89, Test_acc 58.87
2024-09-13 19:51:33,459 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.26, Spatial_loss 1.23, Flat_loss 0.10, Train_acc 94.20, Test_acc 60.50
2024-09-13 19:51:43,866 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.27, Spatial_loss 1.22, Flat_loss 0.09, Train_acc 93.56, Test_acc 58.13
2024-09-13 19:51:50,326 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.10, Train_acc 94.14, Test_acc 60.60
2024-09-13 19:51:58,381 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.10, Train_acc 94.41, Test_acc 61.33
2024-09-13 19:52:04,848 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.24, Spatial_loss 1.21, Flat_loss 0.09, Train_acc 94.56, Test_acc 59.80
2024-09-13 19:52:12,598 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.09, Train_acc 94.73, Test_acc 61.83
2024-09-13 19:52:19,081 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.09, Train_acc 95.29, Test_acc 59.83
2024-09-13 19:52:26,402 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.09, Train_acc 94.86, Test_acc 61.50
2024-09-13 19:52:35,507 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.09, Train_acc 94.94, Test_acc 60.13
2024-09-13 19:52:41,925 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.09, Train_acc 94.73, Test_acc 59.17
2024-09-13 19:52:50,169 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 95.80, Test_acc 60.17
2024-09-13 19:52:56,669 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 95.44, Test_acc 55.33
2024-09-13 19:53:04,420 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 95.59, Test_acc 62.00
2024-09-13 19:53:10,811 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 95.86, Test_acc 59.70
2024-09-13 19:53:18,738 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 95.70, Test_acc 59.73
2024-09-13 19:53:25,245 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 96.34, Test_acc 60.60
2024-09-13 19:53:32,884 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 96.23, Test_acc 61.87
2024-09-13 19:53:39,519 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 96.69, Test_acc 61.90
2024-09-13 19:53:46,962 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.09, Train_acc 96.24, Test_acc 60.40
2024-09-13 19:53:53,725 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.19, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 96.31, Test_acc 62.10
2024-09-13 19:54:01,259 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.09, Train_acc 96.83, Test_acc 61.73
2024-09-13 19:54:07,986 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 96.54, Test_acc 62.63
2024-09-13 19:54:15,309 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.09, Train_acc 97.10, Test_acc 63.10
2024-09-13 19:54:22,366 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 97.09, Test_acc 62.83
2024-09-13 19:54:29,420 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 97.00, Test_acc 61.43
2024-09-13 19:54:38,501 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 97.16, Test_acc 62.30
2024-09-13 19:54:44,969 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.09, Train_acc 97.64, Test_acc 62.23
2024-09-13 19:54:53,935 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.09, Train_acc 97.21, Test_acc 62.30
2024-09-13 19:55:01,198 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.09, Train_acc 97.69, Test_acc 62.30
2024-09-13 19:55:09,160 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 97.40, Test_acc 61.53
2024-09-13 19:55:15,588 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 97.90, Test_acc 61.93
2024-09-13 19:55:23,184 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.15, Spatial_loss 0.98, Flat_loss 0.08, Train_acc 97.96, Test_acc 62.00
2024-09-13 19:55:29,628 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.08, Train_acc 97.74, Test_acc 62.57
2024-09-13 19:55:37,375 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 98.03, Test_acc 61.87
2024-09-13 19:55:43,840 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.08, Train_acc 97.97, Test_acc 62.60
2024-09-13 19:55:51,721 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 97.89, Test_acc 62.60
2024-09-13 19:55:58,269 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 98.51, Test_acc 62.77
2024-09-13 19:56:06,122 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 98.04, Test_acc 61.67
2024-09-13 19:56:12,594 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.08, Train_acc 98.00, Test_acc 62.53
2024-09-13 19:56:20,266 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 98.26, Test_acc 62.63
2024-09-13 19:56:26,743 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 98.39, Test_acc 63.30
2024-09-13 19:56:34,647 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 98.27, Test_acc 62.33
2024-09-13 19:56:41,192 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 98.51, Test_acc 62.30
2024-09-13 19:56:48,843 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.50, Test_acc 62.97
2024-09-13 19:56:55,338 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.54, Test_acc 62.27
2024-09-13 19:57:03,680 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 98.49, Test_acc 62.40
2024-09-13 19:57:10,137 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 98.66, Test_acc 63.07
2024-09-13 19:57:17,770 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.08, Train_acc 98.47, Test_acc 62.63
2024-09-13 19:57:24,528 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.08, Train_acc 98.83, Test_acc 62.47
2024-09-13 19:57:32,155 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.08, Train_acc 98.77, Test_acc 62.47
2024-09-13 19:57:38,724 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.13, Spatial_loss 0.85, Flat_loss 0.08, Train_acc 98.66, Test_acc 62.97
2024-09-13 19:57:46,265 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.08, Train_acc 98.84, Test_acc 63.33
2024-09-13 19:57:52,953 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.08, Train_acc 98.61, Test_acc 63.33
2024-09-13 19:58:00,340 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.13, Spatial_loss 0.84, Flat_loss 0.08, Train_acc 98.84, Test_acc 63.73
2024-09-13 19:58:07,439 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.08, Train_acc 98.77, Test_acc 63.07
2024-09-13 19:58:17,771 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.08, Train_acc 98.96, Test_acc 63.37
2024-09-13 19:58:24,396 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 98.89, Test_acc 63.50
2024-09-13 19:58:32,134 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.08, Train_acc 98.93, Test_acc 63.37
2024-09-13 19:58:38,987 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 99.13, Test_acc 63.20
2024-09-13 19:58:46,477 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 99.01, Test_acc 63.30
2024-09-13 19:58:53,436 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 98.74, Test_acc 63.27
2024-09-13 19:59:00,920 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 98.77, Test_acc 63.53
2024-09-13 19:59:08,271 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.12, Spatial_loss 0.82, Flat_loss 0.08, Train_acc 98.91, Test_acc 63.33
2024-09-13 19:59:15,223 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 98.89, Test_acc 63.60
2024-09-13 19:59:24,452 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 99.16, Test_acc 63.53
2024-09-13 19:59:30,833 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.08, Train_acc 98.83, Test_acc 63.13
2024-09-13 19:59:39,123 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 99.13, Test_acc 63.40
2024-09-13 19:59:45,473 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 98.81, Test_acc 63.47
2024-09-13 19:59:53,079 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.08, Train_acc 98.79, Test_acc 63.53
2024-09-13 19:59:59,364 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.80, Flat_loss 0.08, Train_acc 99.04, Test_acc 63.70
2024-09-13 19:59:59,365 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 19:59:59,365 [base.py] => Reducing exemplars...(100 per classes)
2024-09-13 20:00:04,962 [base.py] => Constructing exemplars...(100 per classes)
2024-09-13 20:00:12,310 [podnet.py] => The size of finetune dataset: 3000
2024-09-13 20:00:15,845 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.06, Train_acc 98.80, Test_acc 64.27
2024-09-13 20:00:20,558 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.05, Train_acc 98.77, Test_acc 64.07
2024-09-13 20:00:24,477 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.05, Train_acc 98.73, Test_acc 64.80
2024-09-13 20:00:28,135 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.05, Train_acc 98.93, Test_acc 64.57
2024-09-13 20:00:31,975 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 0.83, Flat_loss 0.05, Train_acc 98.90, Test_acc 64.60
2024-09-13 20:00:36,874 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.06, Train_acc 99.17, Test_acc 64.63
2024-09-13 20:00:40,443 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.05, Train_acc 98.83, Test_acc 64.90
2024-09-13 20:00:44,014 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.05, Train_acc 99.13, Test_acc 65.10
2024-09-13 20:00:48,183 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.05, Train_acc 98.90, Test_acc 65.13
2024-09-13 20:00:53,149 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.05, Train_acc 98.80, Test_acc 65.13
2024-09-13 20:00:56,775 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.05, Train_acc 99.40, Test_acc 65.13
2024-09-13 20:01:00,400 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.05, Train_acc 98.97, Test_acc 65.37
2024-09-13 20:01:04,903 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 0.82, Flat_loss 0.05, Train_acc 99.20, Test_acc 65.20
2024-09-13 20:01:09,908 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.05, Train_acc 99.10, Test_acc 65.17
2024-09-13 20:01:13,495 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.05, Train_acc 99.00, Test_acc 65.37
2024-09-13 20:01:17,067 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.80, Flat_loss 0.05, Train_acc 99.13, Test_acc 65.37
2024-09-13 20:01:21,639 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.05, Train_acc 98.90, Test_acc 65.20
2024-09-13 20:01:27,578 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.05, Train_acc 99.13, Test_acc 65.37
2024-09-13 20:01:31,226 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.05, Train_acc 99.20, Test_acc 65.37
2024-09-13 20:01:34,840 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.05, Train_acc 99.23, Test_acc 65.23
2024-09-13 20:01:34,842 [base.py] => Reducing exemplars...(66 per classes)
2024-09-13 20:01:40,934 [base.py] => Constructing exemplars...(66 per classes)
2024-09-13 20:01:49,668 [podnet.py] => Exemplar size: 1980
2024-09-13 20:01:49,668 [trainer.py] => CNN: {'total': 65.23, '00-09': 73.6, '10-19': 45.7, '20-29': 76.4, 'old': 59.65, 'new': 76.4}
2024-09-13 20:01:49,669 [trainer.py] => NME: {'total': 61.53, '00-09': 81.6, '10-19': 37.7, '20-29': 65.3, 'old': 59.65, 'new': 65.3}
2024-09-13 20:01:49,669 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23]
2024-09-13 20:01:49,669 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67]
2024-09-13 20:01:49,669 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53]
2024-09-13 20:01:49,669 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23]

2024-09-13 20:01:49,670 [trainer.py] => All params: 482705
2024-09-13 20:01:49,670 [trainer.py] => Trainable params: 482705
2024-09-13 20:01:49,671 [podnet.py] => Learning on 30-40
2024-09-13 20:01:49,724 [podnet.py] => Adaptive factor: 2.0
2024-09-13 20:01:58,700 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 2.63, Spatial_loss 2.21, Flat_loss 0.15, Train_acc 41.22, Test_acc 25.78
2024-09-13 20:02:05,382 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 1.50, Spatial_loss 2.06, Flat_loss 0.11, Train_acc 55.52, Test_acc 33.92
2024-09-13 20:02:13,320 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 1.38, Spatial_loss 2.02, Flat_loss 0.11, Train_acc 59.03, Test_acc 39.05
2024-09-13 20:02:19,891 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 1.30, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 61.81, Test_acc 35.65
2024-09-13 20:02:27,742 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 63.91, Test_acc 39.35
2024-09-13 20:02:34,341 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 1.19, Spatial_loss 1.95, Flat_loss 0.10, Train_acc 65.53, Test_acc 43.62
2024-09-13 20:02:42,496 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 1.11, Spatial_loss 1.85, Flat_loss 0.10, Train_acc 67.78, Test_acc 41.18
2024-09-13 20:02:49,096 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 1.08, Spatial_loss 1.86, Flat_loss 0.10, Train_acc 68.38, Test_acc 37.88
2024-09-13 20:02:56,956 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 1.07, Spatial_loss 1.91, Flat_loss 0.10, Train_acc 68.84, Test_acc 35.22
2024-09-13 20:03:03,570 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 1.03, Spatial_loss 1.84, Flat_loss 0.10, Train_acc 70.69, Test_acc 41.48
2024-09-13 20:03:11,737 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.99, Spatial_loss 1.83, Flat_loss 0.10, Train_acc 71.63, Test_acc 41.68
2024-09-13 20:03:18,425 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.98, Spatial_loss 1.83, Flat_loss 0.10, Train_acc 72.03, Test_acc 39.62
2024-09-13 20:03:26,523 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.94, Spatial_loss 1.80, Flat_loss 0.10, Train_acc 73.11, Test_acc 43.92
2024-09-13 20:03:33,237 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.95, Spatial_loss 1.84, Flat_loss 0.10, Train_acc 72.52, Test_acc 46.30
2024-09-13 20:03:41,454 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.92, Spatial_loss 1.75, Flat_loss 0.10, Train_acc 73.30, Test_acc 45.12
2024-09-13 20:03:48,262 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.90, Spatial_loss 1.81, Flat_loss 0.10, Train_acc 74.48, Test_acc 44.62
2024-09-13 20:03:56,374 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.89, Spatial_loss 1.81, Flat_loss 0.10, Train_acc 74.70, Test_acc 43.45
2024-09-13 20:04:03,089 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.88, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 74.80, Test_acc 43.30
2024-09-13 20:04:11,287 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.88, Spatial_loss 1.79, Flat_loss 0.10, Train_acc 74.58, Test_acc 46.42
2024-09-13 20:04:17,995 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.82, Spatial_loss 1.76, Flat_loss 0.10, Train_acc 76.83, Test_acc 44.88
2024-09-13 20:04:25,741 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.82, Spatial_loss 1.74, Flat_loss 0.10, Train_acc 76.68, Test_acc 45.92
2024-09-13 20:04:32,371 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.83, Spatial_loss 1.82, Flat_loss 0.11, Train_acc 76.55, Test_acc 43.72
2024-09-13 20:04:42,492 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.81, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 76.86, Test_acc 46.10
2024-09-13 20:04:49,275 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.80, Spatial_loss 1.79, Flat_loss 0.10, Train_acc 77.34, Test_acc 41.42
2024-09-13 20:04:57,332 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.78, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 77.98, Test_acc 44.38
2024-09-13 20:05:04,115 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.78, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 78.14, Test_acc 43.18
2024-09-13 20:05:12,425 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.77, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 78.52, Test_acc 42.25
2024-09-13 20:05:19,252 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.77, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 78.48, Test_acc 44.95
2024-09-13 20:05:27,680 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.75, Spatial_loss 1.69, Flat_loss 0.10, Train_acc 79.05, Test_acc 45.52
2024-09-13 20:05:34,319 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.71, Spatial_loss 1.70, Flat_loss 0.10, Train_acc 80.01, Test_acc 44.00
2024-09-13 20:05:42,403 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.74, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 79.24, Test_acc 44.35
2024-09-13 20:05:49,128 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.72, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 80.27, Test_acc 46.40
2024-09-13 20:05:57,397 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.72, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 79.93, Test_acc 45.55
2024-09-13 20:06:04,259 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.70, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 80.64, Test_acc 41.58
2024-09-13 20:06:12,906 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.68, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 80.69, Test_acc 45.72
2024-09-13 20:06:19,734 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.68, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 81.58, Test_acc 48.82
2024-09-13 20:06:28,071 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.66, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 81.17, Test_acc 44.85
2024-09-13 20:06:34,981 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.69, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 80.77, Test_acc 42.22
2024-09-13 20:06:43,287 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.67, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 81.69, Test_acc 41.35
2024-09-13 20:06:50,110 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.68, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 81.22, Test_acc 44.05
2024-09-13 20:06:58,356 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.66, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 82.13, Test_acc 40.55
2024-09-13 20:07:05,204 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.62, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 82.94, Test_acc 45.00
2024-09-13 20:07:13,604 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.64, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 82.48, Test_acc 45.35
2024-09-13 20:07:20,405 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.67, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 81.69, Test_acc 46.28
2024-09-13 20:07:28,618 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.63, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 82.45, Test_acc 44.30
2024-09-13 20:07:35,435 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.60, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 83.37, Test_acc 45.55
2024-09-13 20:07:43,699 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.61, Spatial_loss 1.69, Flat_loss 0.11, Train_acc 83.31, Test_acc 43.80
2024-09-13 20:07:52,879 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.61, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 82.98, Test_acc 48.42
2024-09-13 20:08:01,633 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.60, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 84.01, Test_acc 47.60
2024-09-13 20:08:08,223 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.58, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 84.76, Test_acc 44.60
2024-09-13 20:08:16,268 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.59, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 84.18, Test_acc 42.22
2024-09-13 20:08:22,942 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.59, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 83.52, Test_acc 47.05
2024-09-13 20:08:30,874 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.57, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 83.71, Test_acc 44.85
2024-09-13 20:08:37,446 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.57, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 84.61, Test_acc 47.80
2024-09-13 20:08:45,390 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.55, Spatial_loss 1.63, Flat_loss 0.11, Train_acc 85.17, Test_acc 46.78
2024-09-13 20:08:51,996 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.55, Spatial_loss 1.62, Flat_loss 0.11, Train_acc 85.53, Test_acc 45.30
2024-09-13 20:08:59,746 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.56, Spatial_loss 1.63, Flat_loss 0.11, Train_acc 84.96, Test_acc 45.10
2024-09-13 20:09:06,293 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.55, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 84.57, Test_acc 42.58
2024-09-13 20:09:14,172 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.56, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 84.77, Test_acc 47.12
2024-09-13 20:09:20,719 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.55, Spatial_loss 1.64, Flat_loss 0.11, Train_acc 85.06, Test_acc 46.02
2024-09-13 20:09:28,531 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.52, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 85.67, Test_acc 47.02
2024-09-13 20:09:35,149 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.49, Spatial_loss 1.58, Flat_loss 0.11, Train_acc 87.56, Test_acc 45.92
2024-09-13 20:09:43,181 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.49, Spatial_loss 1.59, Flat_loss 0.11, Train_acc 87.21, Test_acc 44.62
2024-09-13 20:09:49,753 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.52, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 85.80, Test_acc 43.20
2024-09-13 20:09:57,529 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.51, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 86.59, Test_acc 43.35
2024-09-13 20:10:04,094 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.50, Spatial_loss 1.59, Flat_loss 0.11, Train_acc 86.92, Test_acc 44.70
2024-09-13 20:10:11,908 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.49, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 87.52, Test_acc 48.08
2024-09-13 20:10:18,688 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.48, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 87.34, Test_acc 47.85
2024-09-13 20:10:26,647 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.50, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 86.68, Test_acc 48.32
2024-09-13 20:10:33,285 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.47, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 87.92, Test_acc 46.92
2024-09-13 20:10:41,399 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.46, Spatial_loss 1.53, Flat_loss 0.11, Train_acc 88.01, Test_acc 48.52
2024-09-13 20:10:48,354 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.45, Spatial_loss 1.53, Flat_loss 0.10, Train_acc 88.31, Test_acc 46.65
2024-09-13 20:10:57,570 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.46, Spatial_loss 1.54, Flat_loss 0.11, Train_acc 88.35, Test_acc 49.85
2024-09-13 20:11:07,211 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.44, Spatial_loss 1.50, Flat_loss 0.10, Train_acc 88.58, Test_acc 50.42
2024-09-13 20:11:16,975 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.45, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 87.92, Test_acc 46.60
2024-09-13 20:11:23,621 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.42, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 89.26, Test_acc 45.05
2024-09-13 20:11:31,454 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.42, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 89.30, Test_acc 47.45
2024-09-13 20:11:38,145 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.41, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 89.71, Test_acc 46.32
2024-09-13 20:11:46,204 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.43, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 89.01, Test_acc 47.98
2024-09-13 20:11:52,780 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.40, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 90.29, Test_acc 48.50
2024-09-13 20:12:00,493 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.39, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 90.24, Test_acc 49.78
2024-09-13 20:12:06,999 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.38, Spatial_loss 1.48, Flat_loss 0.10, Train_acc 90.96, Test_acc 48.20
2024-09-13 20:12:14,832 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.39, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 90.64, Test_acc 50.28
2024-09-13 20:12:21,492 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.38, Spatial_loss 1.45, Flat_loss 0.10, Train_acc 90.69, Test_acc 47.48
2024-09-13 20:12:29,382 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.39, Spatial_loss 1.44, Flat_loss 0.10, Train_acc 90.64, Test_acc 46.42
2024-09-13 20:12:35,939 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.38, Spatial_loss 1.44, Flat_loss 0.10, Train_acc 90.29, Test_acc 47.42
2024-09-13 20:12:43,727 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.36, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 91.45, Test_acc 47.80
2024-09-13 20:12:50,360 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.35, Spatial_loss 1.40, Flat_loss 0.10, Train_acc 91.86, Test_acc 49.15
2024-09-13 20:12:58,156 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.36, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 91.46, Test_acc 48.80
2024-09-13 20:13:04,756 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.37, Spatial_loss 1.42, Flat_loss 0.10, Train_acc 90.87, Test_acc 48.85
2024-09-13 20:13:12,618 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.35, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 91.58, Test_acc 51.18
2024-09-13 20:13:19,300 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.34, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 91.92, Test_acc 47.98
2024-09-13 20:13:27,050 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.34, Spatial_loss 1.33, Flat_loss 0.10, Train_acc 92.25, Test_acc 50.25
2024-09-13 20:13:33,617 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.35, Flat_loss 0.10, Train_acc 92.19, Test_acc 49.08
2024-09-13 20:13:41,566 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.31, Spatial_loss 1.35, Flat_loss 0.10, Train_acc 93.32, Test_acc 49.72
2024-09-13 20:13:48,302 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.32, Spatial_loss 1.31, Flat_loss 0.10, Train_acc 92.92, Test_acc 48.38
2024-09-13 20:13:56,242 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.30, Spatial_loss 1.33, Flat_loss 0.10, Train_acc 93.52, Test_acc 50.52
2024-09-13 20:14:03,515 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.30, Spatial_loss 1.34, Flat_loss 0.10, Train_acc 93.75, Test_acc 50.62
2024-09-13 20:14:14,033 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.29, Spatial_loss 1.28, Flat_loss 0.10, Train_acc 93.90, Test_acc 50.52
2024-09-13 20:14:20,867 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.30, Spatial_loss 1.31, Flat_loss 0.10, Train_acc 93.32, Test_acc 48.70
2024-09-13 20:14:29,193 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.29, Spatial_loss 1.28, Flat_loss 0.10, Train_acc 93.87, Test_acc 51.72
2024-09-13 20:14:35,941 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.29, Spatial_loss 1.29, Flat_loss 0.10, Train_acc 93.93, Test_acc 49.20
2024-09-13 20:14:44,133 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.28, Spatial_loss 1.29, Flat_loss 0.10, Train_acc 94.00, Test_acc 49.82
2024-09-13 20:14:50,967 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.10, Train_acc 94.64, Test_acc 49.80
2024-09-13 20:14:59,053 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.29, Spatial_loss 1.28, Flat_loss 0.10, Train_acc 93.51, Test_acc 49.52
2024-09-13 20:15:05,743 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.27, Spatial_loss 1.23, Flat_loss 0.09, Train_acc 94.41, Test_acc 49.42
2024-09-13 20:15:13,890 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.09, Train_acc 94.90, Test_acc 50.20
2024-09-13 20:15:20,833 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.10, Train_acc 95.14, Test_acc 47.62
2024-09-13 20:15:28,884 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.09, Train_acc 95.24, Test_acc 50.38
2024-09-13 20:15:35,526 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.09, Train_acc 95.49, Test_acc 51.15
2024-09-13 20:15:43,517 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.09, Train_acc 95.73, Test_acc 51.40
2024-09-13 20:15:50,156 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.09, Train_acc 95.77, Test_acc 50.72
2024-09-13 20:15:58,097 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.09, Train_acc 95.57, Test_acc 51.75
2024-09-13 20:16:04,777 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.09, Train_acc 95.74, Test_acc 50.48
2024-09-13 20:16:12,533 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.09, Train_acc 96.39, Test_acc 50.45
2024-09-13 20:16:19,339 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 96.36, Test_acc 51.68
2024-09-13 20:16:27,559 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 96.16, Test_acc 50.95
2024-09-13 20:16:34,482 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 96.16, Test_acc 51.42
2024-09-13 20:16:42,804 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 96.65, Test_acc 50.30
2024-09-13 20:16:49,711 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 96.89, Test_acc 49.85
2024-09-13 20:16:58,195 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 97.11, Test_acc 50.30
2024-09-13 20:17:04,897 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.09, Train_acc 97.05, Test_acc 50.82
2024-09-13 20:17:14,348 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.09, Train_acc 96.95, Test_acc 51.92
2024-09-13 20:17:21,458 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.09, Train_acc 97.26, Test_acc 52.15
2024-09-13 20:17:29,918 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 97.59, Test_acc 49.72
2024-09-13 20:17:36,695 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 97.39, Test_acc 52.05
2024-09-13 20:17:45,010 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 97.65, Test_acc 50.60
2024-09-13 20:17:51,821 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 97.45, Test_acc 51.60
2024-09-13 20:17:59,940 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 97.55, Test_acc 51.90
2024-09-13 20:18:06,565 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 97.81, Test_acc 51.50
2024-09-13 20:18:14,695 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.17, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 97.75, Test_acc 52.58
2024-09-13 20:18:21,588 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.08, Train_acc 97.81, Test_acc 52.10
2024-09-13 20:18:29,912 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 97.95, Test_acc 52.52
2024-09-13 20:18:36,674 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 97.94, Test_acc 50.88
2024-09-13 20:18:44,854 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.09, Train_acc 98.07, Test_acc 52.65
2024-09-13 20:18:51,745 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 97.72, Test_acc 52.28
2024-09-13 20:18:59,983 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.08, Train_acc 98.02, Test_acc 52.15
2024-09-13 20:19:06,793 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.08, Train_acc 98.32, Test_acc 52.55
2024-09-13 20:19:14,908 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.08, Train_acc 98.21, Test_acc 51.78
2024-09-13 20:19:21,758 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.08, Train_acc 98.18, Test_acc 52.65
2024-09-13 20:19:29,804 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.08, Train_acc 98.38, Test_acc 53.02
2024-09-13 20:19:36,460 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.08, Train_acc 98.42, Test_acc 52.60
2024-09-13 20:19:44,596 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.17, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 97.95, Test_acc 52.70
2024-09-13 20:19:51,325 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.09, Train_acc 98.31, Test_acc 52.32
2024-09-13 20:19:59,683 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.08, Train_acc 98.38, Test_acc 52.90
2024-09-13 20:20:06,408 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 98.31, Test_acc 52.78
2024-09-13 20:20:14,444 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.08, Train_acc 98.28, Test_acc 53.05
2024-09-13 20:20:23,111 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 98.64, Test_acc 52.80
2024-09-13 20:20:32,331 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 98.62, Test_acc 52.25
2024-09-13 20:20:38,907 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 98.60, Test_acc 52.90
2024-09-13 20:20:46,931 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.16, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.50, Test_acc 52.90
2024-09-13 20:20:53,609 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 98.90, Test_acc 52.92
2024-09-13 20:21:01,519 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.77, Test_acc 53.38
2024-09-13 20:21:08,185 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.08, Train_acc 98.42, Test_acc 52.92
2024-09-13 20:21:16,144 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 0.92, Flat_loss 0.08, Train_acc 98.55, Test_acc 53.02
2024-09-13 20:21:22,798 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 98.62, Test_acc 53.05
2024-09-13 20:21:30,958 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.67, Test_acc 53.02
2024-09-13 20:21:37,567 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.08, Train_acc 98.48, Test_acc 52.90
2024-09-13 20:21:45,661 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 98.64, Test_acc 52.75
2024-09-13 20:21:52,317 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.08, Train_acc 98.51, Test_acc 53.10
2024-09-13 20:21:52,318 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 20:21:52,318 [base.py] => Reducing exemplars...(66 per classes)
2024-09-13 20:22:00,637 [base.py] => Constructing exemplars...(66 per classes)
2024-09-13 20:22:07,094 [podnet.py] => The size of finetune dataset: 2640
2024-09-13 20:22:11,576 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.20, Spatial_loss 0.94, Flat_loss 0.06, Train_acc 97.08, Test_acc 56.08
2024-09-13 20:22:16,362 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.05, Train_acc 98.75, Test_acc 55.60
2024-09-13 20:22:19,909 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.05, Train_acc 98.71, Test_acc 56.25
2024-09-13 20:22:23,537 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.05, Train_acc 99.24, Test_acc 55.70
2024-09-13 20:22:27,899 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.05, Train_acc 98.60, Test_acc 56.42
2024-09-13 20:22:32,671 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.05, Train_acc 98.90, Test_acc 56.08
2024-09-13 20:22:36,222 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.05, Train_acc 99.05, Test_acc 56.82
2024-09-13 20:22:39,825 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.05, Train_acc 99.05, Test_acc 56.82
2024-09-13 20:22:44,212 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.05, Train_acc 99.05, Test_acc 57.22
2024-09-13 20:22:49,176 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.05, Train_acc 99.05, Test_acc 57.00
2024-09-13 20:22:52,767 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.05, Train_acc 98.86, Test_acc 57.15
2024-09-13 20:22:56,498 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.05, Train_acc 98.83, Test_acc 56.88
2024-09-13 20:23:00,989 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.05, Train_acc 99.09, Test_acc 57.00
2024-09-13 20:23:05,946 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.05, Train_acc 99.09, Test_acc 57.15
2024-09-13 20:23:09,544 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.05, Train_acc 99.36, Test_acc 57.22
2024-09-13 20:23:13,188 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.05, Train_acc 99.28, Test_acc 57.08
2024-09-13 20:23:17,521 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.05, Train_acc 99.17, Test_acc 57.30
2024-09-13 20:23:22,341 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.05, Train_acc 99.36, Test_acc 57.22
2024-09-13 20:23:27,704 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.05, Train_acc 99.05, Test_acc 57.32
2024-09-13 20:23:31,411 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.05, Train_acc 99.20, Test_acc 57.38
2024-09-13 20:23:31,413 [base.py] => Reducing exemplars...(50 per classes)
2024-09-13 20:23:39,089 [base.py] => Constructing exemplars...(50 per classes)
2024-09-13 20:23:49,349 [podnet.py] => Exemplar size: 2000
2024-09-13 20:23:49,350 [trainer.py] => CNN: {'total': 57.38, '00-09': 67.6, '10-19': 36.6, '20-29': 56.3, '30-39': 69.0, 'old': 53.5, 'new': 69.0}
2024-09-13 20:23:49,350 [trainer.py] => NME: {'total': 52.48, '00-09': 78.3, '10-19': 30.0, '20-29': 47.4, '30-39': 54.2, 'old': 51.9, 'new': 54.2}
2024-09-13 20:23:49,350 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23, 57.38]
2024-09-13 20:23:49,350 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67, 83.42]
2024-09-13 20:23:49,350 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53, 52.48]
2024-09-13 20:23:49,350 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23, 82.1]

2024-09-13 20:23:49,351 [trainer.py] => All params: 489105
2024-09-13 20:23:49,352 [trainer.py] => Trainable params: 489105
2024-09-13 20:23:49,353 [podnet.py] => Learning on 40-50
2024-09-13 20:23:49,443 [podnet.py] => Adaptive factor: 2.23606797749979
2024-09-13 20:23:56,511 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 2.47, Spatial_loss 2.37, Flat_loss 0.16, Train_acc 51.61, Test_acc 29.38
2024-09-13 20:24:05,145 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 1.28, Spatial_loss 2.26, Flat_loss 0.13, Train_acc 64.99, Test_acc 34.82
2024-09-13 20:24:12,135 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 1.11, Spatial_loss 2.19, Flat_loss 0.12, Train_acc 69.34, Test_acc 36.00
2024-09-13 20:24:21,048 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 1.05, Spatial_loss 2.09, Flat_loss 0.11, Train_acc 71.73, Test_acc 36.48
2024-09-13 20:24:28,252 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 1.01, Spatial_loss 2.18, Flat_loss 0.11, Train_acc 73.00, Test_acc 37.28
2024-09-13 20:24:37,137 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.94, Spatial_loss 2.09, Flat_loss 0.11, Train_acc 73.51, Test_acc 39.32
2024-09-13 20:24:43,987 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.91, Spatial_loss 2.00, Flat_loss 0.11, Train_acc 74.57, Test_acc 39.82
2024-09-13 20:24:52,367 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.88, Spatial_loss 2.01, Flat_loss 0.11, Train_acc 76.66, Test_acc 41.08
2024-09-13 20:24:59,351 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.82, Spatial_loss 1.91, Flat_loss 0.10, Train_acc 77.73, Test_acc 40.48
2024-09-13 20:25:07,905 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.84, Spatial_loss 1.94, Flat_loss 0.11, Train_acc 76.59, Test_acc 39.60
2024-09-13 20:25:14,906 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.80, Spatial_loss 1.96, Flat_loss 0.10, Train_acc 78.53, Test_acc 37.64
2024-09-13 20:25:23,460 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.77, Spatial_loss 1.97, Flat_loss 0.11, Train_acc 79.26, Test_acc 40.58
2024-09-13 20:25:30,617 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.75, Spatial_loss 1.89, Flat_loss 0.10, Train_acc 79.76, Test_acc 41.02
2024-09-13 20:25:39,393 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.75, Spatial_loss 1.92, Flat_loss 0.11, Train_acc 79.51, Test_acc 38.52
2024-09-13 20:25:46,405 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.74, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 79.84, Test_acc 40.76
2024-09-13 20:25:54,971 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.72, Spatial_loss 1.94, Flat_loss 0.11, Train_acc 80.99, Test_acc 41.86
2024-09-13 20:26:02,089 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.69, Spatial_loss 1.92, Flat_loss 0.10, Train_acc 81.26, Test_acc 40.38
2024-09-13 20:26:10,972 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.70, Spatial_loss 1.87, Flat_loss 0.11, Train_acc 81.40, Test_acc 41.06
2024-09-13 20:26:17,978 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.69, Spatial_loss 1.90, Flat_loss 0.10, Train_acc 81.17, Test_acc 38.28
2024-09-13 20:26:26,895 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.68, Spatial_loss 1.93, Flat_loss 0.11, Train_acc 81.79, Test_acc 39.68
2024-09-13 20:26:35,756 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.69, Spatial_loss 1.96, Flat_loss 0.11, Train_acc 81.47, Test_acc 40.68
2024-09-13 20:26:44,353 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.65, Spatial_loss 1.87, Flat_loss 0.11, Train_acc 82.70, Test_acc 44.22
2024-09-13 20:26:51,264 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.66, Spatial_loss 1.92, Flat_loss 0.11, Train_acc 82.23, Test_acc 39.86
2024-09-13 20:26:59,650 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.66, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 82.50, Test_acc 42.44
2024-09-13 20:27:06,420 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.65, Spatial_loss 1.93, Flat_loss 0.11, Train_acc 82.76, Test_acc 38.52
2024-09-13 20:27:14,508 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.65, Spatial_loss 1.90, Flat_loss 0.11, Train_acc 82.24, Test_acc 42.62
2024-09-13 20:27:21,254 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.63, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 83.23, Test_acc 43.86
2024-09-13 20:27:29,548 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.62, Spatial_loss 1.87, Flat_loss 0.11, Train_acc 83.57, Test_acc 41.56
2024-09-13 20:27:36,279 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.60, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 84.19, Test_acc 39.50
2024-09-13 20:27:44,299 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.62, Spatial_loss 1.90, Flat_loss 0.11, Train_acc 83.36, Test_acc 38.48
2024-09-13 20:27:51,053 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.60, Spatial_loss 1.83, Flat_loss 0.11, Train_acc 84.10, Test_acc 43.20
2024-09-13 20:27:59,249 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.58, Spatial_loss 1.86, Flat_loss 0.11, Train_acc 85.01, Test_acc 42.54
2024-09-13 20:28:05,927 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.58, Spatial_loss 1.86, Flat_loss 0.11, Train_acc 84.41, Test_acc 42.22
2024-09-13 20:28:14,060 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.56, Spatial_loss 1.81, Flat_loss 0.10, Train_acc 85.16, Test_acc 36.32
2024-09-13 20:28:20,746 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.56, Spatial_loss 1.81, Flat_loss 0.11, Train_acc 85.40, Test_acc 39.58
2024-09-13 20:28:28,875 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.57, Spatial_loss 1.88, Flat_loss 0.11, Train_acc 84.46, Test_acc 43.44
2024-09-13 20:28:35,647 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.56, Spatial_loss 1.81, Flat_loss 0.11, Train_acc 85.06, Test_acc 41.08
2024-09-13 20:28:43,853 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.57, Spatial_loss 1.78, Flat_loss 0.10, Train_acc 84.70, Test_acc 45.52
2024-09-13 20:28:50,696 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.54, Spatial_loss 1.84, Flat_loss 0.11, Train_acc 85.37, Test_acc 42.52
2024-09-13 20:28:59,050 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.55, Spatial_loss 1.82, Flat_loss 0.11, Train_acc 85.41, Test_acc 39.46
2024-09-13 20:29:05,768 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.56, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 84.89, Test_acc 45.20
2024-09-13 20:29:13,839 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.53, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 86.30, Test_acc 39.56
2024-09-13 20:29:20,695 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.55, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 85.81, Test_acc 42.62
2024-09-13 20:29:28,926 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.52, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 86.81, Test_acc 41.06
2024-09-13 20:29:36,737 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.53, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 86.49, Test_acc 44.50
2024-09-13 20:29:47,166 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.52, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 86.07, Test_acc 41.48
2024-09-13 20:29:53,926 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.51, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 86.86, Test_acc 43.22
2024-09-13 20:30:02,267 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.50, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 86.76, Test_acc 43.42
2024-09-13 20:30:09,058 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.51, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 86.53, Test_acc 41.12
2024-09-13 20:30:17,174 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.50, Spatial_loss 1.78, Flat_loss 0.10, Train_acc 87.31, Test_acc 42.14
2024-09-13 20:30:23,960 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.50, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 87.11, Test_acc 43.74
2024-09-13 20:30:32,322 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.47, Spatial_loss 1.68, Flat_loss 0.10, Train_acc 88.31, Test_acc 42.80
2024-09-13 20:30:39,082 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.49, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 87.80, Test_acc 43.18
2024-09-13 20:30:47,257 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.45, Spatial_loss 1.70, Flat_loss 0.10, Train_acc 88.17, Test_acc 40.50
2024-09-13 20:30:54,073 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.45, Spatial_loss 1.71, Flat_loss 0.10, Train_acc 88.90, Test_acc 43.92
2024-09-13 20:31:02,330 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.47, Spatial_loss 1.72, Flat_loss 0.10, Train_acc 88.06, Test_acc 43.92
2024-09-13 20:31:09,143 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.46, Spatial_loss 1.69, Flat_loss 0.10, Train_acc 88.34, Test_acc 41.00
2024-09-13 20:31:17,331 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.46, Spatial_loss 1.72, Flat_loss 0.10, Train_acc 88.16, Test_acc 41.44
2024-09-13 20:31:24,039 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.44, Spatial_loss 1.71, Flat_loss 0.10, Train_acc 88.84, Test_acc 44.68
2024-09-13 20:31:32,409 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.43, Spatial_loss 1.67, Flat_loss 0.10, Train_acc 89.51, Test_acc 42.00
2024-09-13 20:31:39,192 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.43, Spatial_loss 1.67, Flat_loss 0.10, Train_acc 89.56, Test_acc 43.88
2024-09-13 20:31:47,437 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.40, Spatial_loss 1.66, Flat_loss 0.10, Train_acc 90.26, Test_acc 42.00
2024-09-13 20:31:54,098 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.44, Spatial_loss 1.70, Flat_loss 0.10, Train_acc 89.03, Test_acc 41.56
2024-09-13 20:32:02,315 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.43, Spatial_loss 1.71, Flat_loss 0.10, Train_acc 88.99, Test_acc 41.20
2024-09-13 20:32:09,079 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.42, Spatial_loss 1.66, Flat_loss 0.10, Train_acc 89.49, Test_acc 43.20
2024-09-13 20:32:17,431 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.43, Spatial_loss 1.63, Flat_loss 0.10, Train_acc 89.19, Test_acc 46.04
2024-09-13 20:32:24,212 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.41, Spatial_loss 1.65, Flat_loss 0.10, Train_acc 89.53, Test_acc 43.86
2024-09-13 20:32:32,664 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.40, Spatial_loss 1.68, Flat_loss 0.10, Train_acc 90.47, Test_acc 39.18
2024-09-13 20:32:40,445 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.40, Spatial_loss 1.64, Flat_loss 0.10, Train_acc 90.14, Test_acc 42.82
2024-09-13 20:32:51,065 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.40, Spatial_loss 1.64, Flat_loss 0.10, Train_acc 90.26, Test_acc 40.72
2024-09-13 20:32:57,832 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.38, Spatial_loss 1.62, Flat_loss 0.10, Train_acc 91.36, Test_acc 45.10
2024-09-13 20:33:06,026 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.40, Spatial_loss 1.63, Flat_loss 0.10, Train_acc 90.13, Test_acc 45.22
2024-09-13 20:33:12,828 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.39, Spatial_loss 1.64, Flat_loss 0.10, Train_acc 90.70, Test_acc 43.42
2024-09-13 20:33:21,079 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.36, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 91.63, Test_acc 44.04
2024-09-13 20:33:27,868 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.36, Spatial_loss 1.55, Flat_loss 0.10, Train_acc 91.43, Test_acc 45.04
2024-09-13 20:33:36,165 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.37, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 90.96, Test_acc 41.86
2024-09-13 20:33:42,849 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.35, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 92.51, Test_acc 44.44
2024-09-13 20:33:50,991 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.10, Train_acc 92.19, Test_acc 43.22
2024-09-13 20:33:57,796 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.36, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 91.39, Test_acc 44.38
2024-09-13 20:34:06,045 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.37, Spatial_loss 1.57, Flat_loss 0.10, Train_acc 91.07, Test_acc 43.40
2024-09-13 20:34:12,840 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.10, Train_acc 91.36, Test_acc 46.12
2024-09-13 20:34:21,014 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.34, Spatial_loss 1.54, Flat_loss 0.10, Train_acc 91.87, Test_acc 42.58
2024-09-13 20:34:27,755 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.10, Train_acc 91.77, Test_acc 44.18
2024-09-13 20:34:35,999 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.32, Spatial_loss 1.51, Flat_loss 0.10, Train_acc 93.01, Test_acc 45.42
2024-09-13 20:34:42,752 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.32, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 93.00, Test_acc 43.36
2024-09-13 20:34:50,894 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.30, Spatial_loss 1.47, Flat_loss 0.09, Train_acc 93.56, Test_acc 44.84
2024-09-13 20:34:57,707 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.32, Spatial_loss 1.50, Flat_loss 0.10, Train_acc 92.37, Test_acc 44.50
2024-09-13 20:35:06,127 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.50, Flat_loss 0.10, Train_acc 92.46, Test_acc 46.32
2024-09-13 20:35:12,913 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.30, Spatial_loss 1.44, Flat_loss 0.09, Train_acc 93.50, Test_acc 45.34
2024-09-13 20:35:21,145 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.28, Spatial_loss 1.46, Flat_loss 0.09, Train_acc 93.96, Test_acc 46.26
2024-09-13 20:35:27,958 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.31, Spatial_loss 1.45, Flat_loss 0.09, Train_acc 93.27, Test_acc 45.24
2024-09-13 20:35:36,241 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.30, Spatial_loss 1.43, Flat_loss 0.09, Train_acc 93.66, Test_acc 44.04
2024-09-13 20:35:44,243 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.29, Spatial_loss 1.46, Flat_loss 0.09, Train_acc 93.90, Test_acc 45.52
2024-09-13 20:35:53,456 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.28, Spatial_loss 1.43, Flat_loss 0.09, Train_acc 94.71, Test_acc 43.48
2024-09-13 20:36:00,189 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.28, Spatial_loss 1.42, Flat_loss 0.09, Train_acc 94.49, Test_acc 46.88
2024-09-13 20:36:08,444 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.09, Train_acc 94.66, Test_acc 45.70
2024-09-13 20:36:15,227 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.27, Spatial_loss 1.37, Flat_loss 0.09, Train_acc 94.64, Test_acc 42.44
2024-09-13 20:36:23,589 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.26, Spatial_loss 1.38, Flat_loss 0.09, Train_acc 95.01, Test_acc 47.48
2024-09-13 20:36:30,320 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.09, Train_acc 94.84, Test_acc 46.26
2024-09-13 20:36:38,646 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.25, Spatial_loss 1.34, Flat_loss 0.09, Train_acc 95.36, Test_acc 47.08
2024-09-13 20:36:45,509 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.25, Spatial_loss 1.37, Flat_loss 0.09, Train_acc 95.17, Test_acc 44.26
2024-09-13 20:36:53,648 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.24, Spatial_loss 1.35, Flat_loss 0.09, Train_acc 95.54, Test_acc 45.44
2024-09-13 20:37:00,394 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.25, Spatial_loss 1.31, Flat_loss 0.09, Train_acc 95.09, Test_acc 46.56
2024-09-13 20:37:08,482 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 1.31, Flat_loss 0.09, Train_acc 96.27, Test_acc 47.14
2024-09-13 20:37:15,238 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.24, Spatial_loss 1.31, Flat_loss 0.09, Train_acc 95.71, Test_acc 46.82
2024-09-13 20:37:23,431 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.23, Spatial_loss 1.29, Flat_loss 0.09, Train_acc 95.99, Test_acc 45.24
2024-09-13 20:37:30,288 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.24, Spatial_loss 1.32, Flat_loss 0.09, Train_acc 95.76, Test_acc 45.64
2024-09-13 20:37:38,551 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.23, Spatial_loss 1.27, Flat_loss 0.09, Train_acc 95.77, Test_acc 45.92
2024-09-13 20:37:45,307 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.09, Train_acc 96.37, Test_acc 45.82
2024-09-13 20:37:53,739 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.22, Spatial_loss 1.26, Flat_loss 0.08, Train_acc 96.57, Test_acc 46.78
2024-09-13 20:38:00,566 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.21, Spatial_loss 1.26, Flat_loss 0.08, Train_acc 96.79, Test_acc 47.72
2024-09-13 20:38:08,987 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 1.22, Flat_loss 0.08, Train_acc 96.76, Test_acc 45.54
2024-09-13 20:38:15,785 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 1.25, Flat_loss 0.08, Train_acc 96.59, Test_acc 46.52
2024-09-13 20:38:23,985 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.20, Spatial_loss 1.20, Flat_loss 0.08, Train_acc 96.81, Test_acc 46.32
2024-09-13 20:38:31,017 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.08, Train_acc 96.97, Test_acc 46.80
2024-09-13 20:38:39,742 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.08, Train_acc 97.26, Test_acc 47.72
2024-09-13 20:38:49,199 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.19, Spatial_loss 1.22, Flat_loss 0.08, Train_acc 97.41, Test_acc 46.74
2024-09-13 20:38:58,859 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.08, Train_acc 96.96, Test_acc 47.76
2024-09-13 20:39:06,243 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.19, Spatial_loss 1.17, Flat_loss 0.08, Train_acc 97.47, Test_acc 46.90
2024-09-13 20:39:15,847 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.19, Spatial_loss 1.17, Flat_loss 0.08, Train_acc 97.46, Test_acc 47.80
2024-09-13 20:39:22,887 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.08, Train_acc 97.30, Test_acc 47.06
2024-09-13 20:39:31,408 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 1.12, Flat_loss 0.08, Train_acc 97.71, Test_acc 47.08
2024-09-13 20:39:38,218 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.17, Spatial_loss 1.10, Flat_loss 0.08, Train_acc 97.96, Test_acc 47.84
2024-09-13 20:39:46,750 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 1.12, Flat_loss 0.08, Train_acc 97.71, Test_acc 47.34
2024-09-13 20:39:53,568 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 97.86, Test_acc 47.24
2024-09-13 20:40:01,742 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 1.11, Flat_loss 0.08, Train_acc 97.96, Test_acc 47.88
2024-09-13 20:40:08,498 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.08, Train_acc 97.91, Test_acc 47.26
2024-09-13 20:40:16,755 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 98.06, Test_acc 47.56
2024-09-13 20:40:23,576 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.08, Train_acc 98.07, Test_acc 46.32
2024-09-13 20:40:31,705 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.08, Train_acc 98.30, Test_acc 48.16
2024-09-13 20:40:38,490 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.08, Train_acc 98.17, Test_acc 47.80
2024-09-13 20:40:46,920 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.08, Train_acc 98.07, Test_acc 47.36
2024-09-13 20:40:53,674 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.17, Spatial_loss 1.05, Flat_loss 0.08, Train_acc 98.14, Test_acc 47.04
2024-09-13 20:41:01,828 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.08, Train_acc 98.13, Test_acc 47.48
2024-09-13 20:41:08,528 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.08, Train_acc 98.54, Test_acc 47.42
2024-09-13 20:41:16,855 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.16, Spatial_loss 1.04, Flat_loss 0.08, Train_acc 98.33, Test_acc 48.02
2024-09-13 20:41:23,580 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.07, Train_acc 98.31, Test_acc 48.20
2024-09-13 20:41:31,710 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.07, Train_acc 98.49, Test_acc 48.14
2024-09-13 20:41:38,567 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 1.00, Flat_loss 0.07, Train_acc 98.53, Test_acc 47.68
2024-09-13 20:41:49,259 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.16, Spatial_loss 1.02, Flat_loss 0.07, Train_acc 98.26, Test_acc 47.58
2024-09-13 20:41:56,158 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.07, Train_acc 98.36, Test_acc 48.40
2024-09-13 20:42:04,909 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.07, Train_acc 98.36, Test_acc 47.72
2024-09-13 20:42:12,187 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 0.97, Flat_loss 0.07, Train_acc 98.63, Test_acc 48.12
2024-09-13 20:42:20,568 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 98.64, Test_acc 47.88
2024-09-13 20:42:27,305 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 98.66, Test_acc 48.24
2024-09-13 20:42:35,584 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 98.53, Test_acc 47.72
2024-09-13 20:42:42,808 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 98.76, Test_acc 47.92
2024-09-13 20:42:51,346 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 98.71, Test_acc 47.52
2024-09-13 20:42:58,212 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.07, Train_acc 98.73, Test_acc 48.02
2024-09-13 20:43:06,610 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.07, Train_acc 98.74, Test_acc 47.86
2024-09-13 20:43:13,620 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.07, Train_acc 98.89, Test_acc 47.70
2024-09-13 20:43:22,162 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.07, Train_acc 98.77, Test_acc 47.62
2024-09-13 20:43:29,136 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.07, Train_acc 98.60, Test_acc 47.82
2024-09-13 20:43:37,418 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.07, Train_acc 98.54, Test_acc 47.86
2024-09-13 20:43:44,185 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.07, Train_acc 98.44, Test_acc 47.96
2024-09-13 20:43:52,315 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.07, Train_acc 98.97, Test_acc 47.82
2024-09-13 20:43:59,136 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.07, Train_acc 98.74, Test_acc 47.92
2024-09-13 20:44:07,324 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.07, Train_acc 98.73, Test_acc 47.62
2024-09-13 20:44:14,243 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.07, Train_acc 98.73, Test_acc 48.16
2024-09-13 20:44:22,719 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.07, Train_acc 98.84, Test_acc 48.02
2024-09-13 20:44:22,719 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 20:44:22,720 [base.py] => Reducing exemplars...(50 per classes)
2024-09-13 20:44:31,095 [base.py] => Constructing exemplars...(50 per classes)
2024-09-13 20:44:38,797 [podnet.py] => The size of finetune dataset: 2500
2024-09-13 20:44:43,429 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.20, Spatial_loss 0.99, Flat_loss 0.05, Train_acc 97.76, Test_acc 50.76
2024-09-13 20:44:49,288 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 98.76, Test_acc 51.02
2024-09-13 20:44:54,294 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.05, Train_acc 99.08, Test_acc 51.44
2024-09-13 20:44:57,968 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.04, Train_acc 99.00, Test_acc 52.22
2024-09-13 20:45:01,676 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.92, Flat_loss 0.04, Train_acc 99.44, Test_acc 52.02
2024-09-13 20:45:06,440 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.05, Train_acc 98.64, Test_acc 52.40
2024-09-13 20:45:10,512 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.05, Train_acc 98.76, Test_acc 52.70
2024-09-13 20:45:14,333 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 98.88, Test_acc 52.64
2024-09-13 20:45:18,444 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.04, Train_acc 99.00, Test_acc 53.18
2024-09-13 20:45:23,212 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.13, Spatial_loss 0.91, Flat_loss 0.04, Train_acc 99.08, Test_acc 52.92
2024-09-13 20:45:26,883 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.04, Train_acc 99.40, Test_acc 52.94
2024-09-13 20:45:30,596 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.04, Train_acc 99.04, Test_acc 53.54
2024-09-13 20:45:35,367 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.04, Train_acc 99.44, Test_acc 53.00
2024-09-13 20:45:39,336 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.04, Train_acc 99.24, Test_acc 53.22
2024-09-13 20:45:43,071 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.04, Train_acc 99.36, Test_acc 53.08
2024-09-13 20:45:47,370 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.04, Train_acc 99.00, Test_acc 53.42
2024-09-13 20:45:52,067 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.04, Train_acc 99.24, Test_acc 53.16
2024-09-13 20:45:55,827 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.04, Train_acc 99.16, Test_acc 53.60
2024-09-13 20:45:59,561 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.05, Train_acc 99.12, Test_acc 53.26
2024-09-13 20:46:04,360 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.04, Train_acc 99.28, Test_acc 53.36
2024-09-13 20:46:04,362 [base.py] => Reducing exemplars...(40 per classes)
2024-09-13 20:46:12,900 [base.py] => Constructing exemplars...(40 per classes)
2024-09-13 20:46:23,661 [podnet.py] => Exemplar size: 2000
2024-09-13 20:46:23,661 [trainer.py] => CNN: {'total': 53.36, '00-09': 63.4, '10-19': 29.6, '20-29': 46.3, '30-39': 49.8, '40-49': 77.7, 'old': 47.28, 'new': 77.7}
2024-09-13 20:46:23,661 [trainer.py] => NME: {'total': 49.36, '00-09': 76.7, '10-19': 25.7, '20-29': 41.8, '30-39': 39.6, '40-49': 63.0, 'old': 45.95, 'new': 63.0}
2024-09-13 20:46:23,662 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23, 57.38, 53.36]
2024-09-13 20:46:23,662 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67, 83.42, 80.74]
2024-09-13 20:46:23,662 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53, 52.48, 49.36]
2024-09-13 20:46:23,662 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23, 82.1, 80.28]

2024-09-13 20:46:23,663 [trainer.py] => All params: 495505
2024-09-13 20:46:23,663 [trainer.py] => Trainable params: 495505
2024-09-13 20:46:23,664 [podnet.py] => Learning on 50-60
2024-09-13 20:46:23,714 [podnet.py] => Adaptive factor: 2.449489742783178
2024-09-13 20:46:31,769 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 2.76, Spatial_loss 2.48, Flat_loss 0.18, Train_acc 43.30, Test_acc 27.00
2024-09-13 20:46:41,589 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 1.50, Spatial_loss 2.41, Flat_loss 0.14, Train_acc 56.63, Test_acc 28.83
2024-09-13 20:46:48,817 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 1.36, Spatial_loss 2.30, Flat_loss 0.12, Train_acc 61.23, Test_acc 31.90
2024-09-13 20:46:58,690 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 1.28, Spatial_loss 2.18, Flat_loss 0.12, Train_acc 63.74, Test_acc 33.15
2024-09-13 20:47:05,800 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 1.21, Spatial_loss 2.18, Flat_loss 0.12, Train_acc 65.66, Test_acc 32.12
2024-09-13 20:47:14,661 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 1.19, Spatial_loss 2.22, Flat_loss 0.12, Train_acc 65.79, Test_acc 35.43
2024-09-13 20:47:21,798 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 1.12, Spatial_loss 2.14, Flat_loss 0.11, Train_acc 68.67, Test_acc 30.02
2024-09-13 20:47:30,866 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 1.08, Spatial_loss 2.15, Flat_loss 0.11, Train_acc 68.84, Test_acc 35.67
2024-09-13 20:47:37,899 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 1.05, Spatial_loss 2.09, Flat_loss 0.11, Train_acc 70.49, Test_acc 32.80
2024-09-13 20:47:48,237 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 1.04, Spatial_loss 2.14, Flat_loss 0.11, Train_acc 70.87, Test_acc 33.02
2024-09-13 20:47:55,244 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 1.00, Spatial_loss 2.16, Flat_loss 0.11, Train_acc 71.97, Test_acc 31.83
2024-09-13 20:48:03,580 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 2.05, Flat_loss 0.11, Train_acc 72.76, Test_acc 34.13
2024-09-13 20:48:10,810 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.95, Spatial_loss 2.12, Flat_loss 0.11, Train_acc 73.51, Test_acc 33.98
2024-09-13 20:48:19,794 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.93, Spatial_loss 2.05, Flat_loss 0.11, Train_acc 74.74, Test_acc 35.15
2024-09-13 20:48:26,827 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.93, Spatial_loss 2.09, Flat_loss 0.11, Train_acc 74.20, Test_acc 31.97
2024-09-13 20:48:35,671 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.91, Spatial_loss 2.10, Flat_loss 0.12, Train_acc 74.81, Test_acc 36.35
2024-09-13 20:48:42,717 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.91, Spatial_loss 2.09, Flat_loss 0.12, Train_acc 74.20, Test_acc 37.27
2024-09-13 20:48:51,547 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.89, Spatial_loss 2.04, Flat_loss 0.11, Train_acc 75.76, Test_acc 36.22
2024-09-13 20:48:58,693 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.87, Spatial_loss 2.09, Flat_loss 0.11, Train_acc 76.86, Test_acc 34.18
2024-09-13 20:49:07,519 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.83, Spatial_loss 1.99, Flat_loss 0.11, Train_acc 77.49, Test_acc 34.03
2024-09-13 20:49:14,570 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.85, Spatial_loss 2.02, Flat_loss 0.11, Train_acc 75.93, Test_acc 37.82
2024-09-13 20:49:23,468 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.84, Spatial_loss 2.05, Flat_loss 0.12, Train_acc 77.41, Test_acc 35.78
2024-09-13 20:49:30,493 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.81, Spatial_loss 1.97, Flat_loss 0.11, Train_acc 78.24, Test_acc 34.93
2024-09-13 20:49:39,197 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.79, Spatial_loss 2.01, Flat_loss 0.11, Train_acc 78.81, Test_acc 36.42
2024-09-13 20:49:46,196 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.80, Spatial_loss 2.03, Flat_loss 0.11, Train_acc 77.70, Test_acc 39.73
2024-09-13 20:49:55,057 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.78, Spatial_loss 2.02, Flat_loss 0.12, Train_acc 78.47, Test_acc 36.80
2024-09-13 20:50:02,126 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.78, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 78.01, Test_acc 33.67
2024-09-13 20:50:10,799 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.78, Spatial_loss 2.06, Flat_loss 0.12, Train_acc 79.13, Test_acc 36.13
2024-09-13 20:50:17,805 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.74, Spatial_loss 2.01, Flat_loss 0.12, Train_acc 79.81, Test_acc 35.15
2024-09-13 20:50:26,752 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.74, Spatial_loss 1.94, Flat_loss 0.11, Train_acc 79.69, Test_acc 37.78
2024-09-13 20:50:33,751 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.73, Spatial_loss 1.98, Flat_loss 0.11, Train_acc 80.01, Test_acc 36.27
2024-09-13 20:50:44,318 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.71, Spatial_loss 1.97, Flat_loss 0.11, Train_acc 80.76, Test_acc 35.53
2024-09-13 20:50:51,535 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.74, Spatial_loss 1.97, Flat_loss 0.12, Train_acc 79.69, Test_acc 30.30
2024-09-13 20:51:00,532 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.73, Spatial_loss 2.09, Flat_loss 0.12, Train_acc 80.71, Test_acc 38.15
2024-09-13 20:51:07,563 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.73, Spatial_loss 1.95, Flat_loss 0.12, Train_acc 80.16, Test_acc 35.32
2024-09-13 20:51:16,213 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.71, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 81.56, Test_acc 34.32
2024-09-13 20:51:23,827 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.72, Spatial_loss 1.94, Flat_loss 0.11, Train_acc 80.73, Test_acc 40.32
2024-09-13 20:51:33,302 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.70, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 81.26, Test_acc 32.97
2024-09-13 20:51:40,468 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.70, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 80.94, Test_acc 33.17
2024-09-13 20:51:49,682 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.65, Spatial_loss 1.91, Flat_loss 0.11, Train_acc 83.31, Test_acc 37.45
2024-09-13 20:51:57,026 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.70, Spatial_loss 1.97, Flat_loss 0.12, Train_acc 81.04, Test_acc 33.73
2024-09-13 20:52:06,517 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.68, Spatial_loss 1.93, Flat_loss 0.11, Train_acc 82.27, Test_acc 36.73
2024-09-13 20:52:13,806 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.66, Spatial_loss 1.90, Flat_loss 0.11, Train_acc 82.27, Test_acc 38.38
2024-09-13 20:52:23,000 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.65, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 82.50, Test_acc 38.58
2024-09-13 20:52:30,245 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.67, Spatial_loss 1.95, Flat_loss 0.12, Train_acc 82.03, Test_acc 37.42
2024-09-13 20:52:39,395 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.65, Spatial_loss 1.96, Flat_loss 0.12, Train_acc 82.59, Test_acc 36.27
2024-09-13 20:52:46,655 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.63, Spatial_loss 1.94, Flat_loss 0.12, Train_acc 83.50, Test_acc 36.48
2024-09-13 20:52:56,092 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.62, Spatial_loss 1.90, Flat_loss 0.11, Train_acc 83.16, Test_acc 39.05
2024-09-13 20:53:03,243 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.60, Spatial_loss 1.89, Flat_loss 0.11, Train_acc 83.96, Test_acc 35.00
2024-09-13 20:53:12,299 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.63, Spatial_loss 1.86, Flat_loss 0.11, Train_acc 83.26, Test_acc 36.20
2024-09-13 20:53:19,415 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.60, Spatial_loss 1.89, Flat_loss 0.11, Train_acc 84.43, Test_acc 37.17
2024-09-13 20:53:28,358 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.61, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 84.00, Test_acc 33.97
2024-09-13 20:53:37,731 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.63, Spatial_loss 1.89, Flat_loss 0.12, Train_acc 83.33, Test_acc 37.57
2024-09-13 20:53:47,878 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.61, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 83.94, Test_acc 37.43
2024-09-13 20:53:55,152 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.56, Spatial_loss 1.87, Flat_loss 0.11, Train_acc 85.61, Test_acc 35.52
2024-09-13 20:54:04,333 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.56, Spatial_loss 1.90, Flat_loss 0.11, Train_acc 85.37, Test_acc 38.60
2024-09-13 20:54:11,556 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.58, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 84.93, Test_acc 37.95
2024-09-13 20:54:20,651 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.56, Spatial_loss 1.85, Flat_loss 0.11, Train_acc 85.76, Test_acc 33.20
2024-09-13 20:54:27,985 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.58, Spatial_loss 1.89, Flat_loss 0.12, Train_acc 84.53, Test_acc 35.45
2024-09-13 20:54:37,217 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.58, Spatial_loss 1.83, Flat_loss 0.11, Train_acc 84.53, Test_acc 35.00
2024-09-13 20:54:44,370 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.56, Spatial_loss 1.82, Flat_loss 0.11, Train_acc 85.47, Test_acc 37.68
2024-09-13 20:54:53,635 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.54, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 85.94, Test_acc 40.22
2024-09-13 20:55:00,904 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.51, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 87.36, Test_acc 38.02
2024-09-13 20:55:10,384 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.54, Spatial_loss 1.83, Flat_loss 0.11, Train_acc 85.99, Test_acc 35.77
2024-09-13 20:55:17,611 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.54, Spatial_loss 1.78, Flat_loss 0.11, Train_acc 85.96, Test_acc 37.52
2024-09-13 20:55:27,199 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.51, Spatial_loss 1.82, Flat_loss 0.11, Train_acc 87.39, Test_acc 37.83
2024-09-13 20:55:34,583 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 87.76, Test_acc 37.22
2024-09-13 20:55:44,147 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.52, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 86.74, Test_acc 39.33
2024-09-13 20:55:51,422 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.50, Spatial_loss 1.79, Flat_loss 0.11, Train_acc 87.39, Test_acc 39.60
2024-09-13 20:56:00,835 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.49, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 87.71, Test_acc 35.57
2024-09-13 20:56:08,186 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.51, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 87.04, Test_acc 35.85
2024-09-13 20:56:17,732 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 87.16, Test_acc 37.80
2024-09-13 20:56:25,740 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.49, Spatial_loss 1.73, Flat_loss 0.11, Train_acc 88.00, Test_acc 37.05
2024-09-13 20:56:37,038 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.48, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 88.04, Test_acc 39.48
2024-09-13 20:56:44,295 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.47, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 88.26, Test_acc 39.23
2024-09-13 20:56:53,548 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.46, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 88.94, Test_acc 41.37
2024-09-13 20:57:00,846 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.47, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 88.36, Test_acc 36.87
2024-09-13 20:57:10,118 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.46, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 88.80, Test_acc 39.62
2024-09-13 20:57:17,366 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.44, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 89.41, Test_acc 39.48
2024-09-13 20:57:26,859 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.46, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 88.53, Test_acc 38.07
2024-09-13 20:57:34,129 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.43, Spatial_loss 1.71, Flat_loss 0.11, Train_acc 89.86, Test_acc 39.45
2024-09-13 20:57:43,520 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.43, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 90.14, Test_acc 38.22
2024-09-13 20:57:50,773 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.42, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 90.16, Test_acc 41.05
2024-09-13 20:58:00,159 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.42, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 89.71, Test_acc 37.85
2024-09-13 20:58:07,374 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.41, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 90.53, Test_acc 38.25
2024-09-13 20:58:16,468 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 1.64, Flat_loss 0.11, Train_acc 89.81, Test_acc 35.45
2024-09-13 20:58:23,632 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.39, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 90.99, Test_acc 39.30
2024-09-13 20:58:32,708 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.38, Spatial_loss 1.56, Flat_loss 0.10, Train_acc 91.50, Test_acc 36.43
2024-09-13 20:58:39,966 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.39, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 91.37, Test_acc 40.07
2024-09-13 20:58:49,051 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.38, Spatial_loss 1.59, Flat_loss 0.10, Train_acc 91.66, Test_acc 37.87
2024-09-13 20:58:56,249 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.37, Spatial_loss 1.52, Flat_loss 0.10, Train_acc 91.93, Test_acc 39.88
2024-09-13 20:59:05,435 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.37, Spatial_loss 1.58, Flat_loss 0.10, Train_acc 91.94, Test_acc 40.68
2024-09-13 20:59:12,559 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.36, Spatial_loss 1.56, Flat_loss 0.10, Train_acc 92.26, Test_acc 37.32
2024-09-13 20:59:22,867 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.10, Train_acc 92.31, Test_acc 40.63
2024-09-13 20:59:30,069 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.36, Spatial_loss 1.55, Flat_loss 0.10, Train_acc 91.99, Test_acc 42.15
2024-09-13 20:59:39,191 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.10, Train_acc 92.63, Test_acc 39.37
2024-09-13 20:59:46,306 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.35, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 92.56, Test_acc 39.27
2024-09-13 20:59:55,402 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.10, Train_acc 92.56, Test_acc 39.35
2024-09-13 21:00:02,640 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.34, Spatial_loss 1.53, Flat_loss 0.10, Train_acc 92.81, Test_acc 38.33
2024-09-13 21:00:11,681 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.10, Train_acc 93.00, Test_acc 40.92
2024-09-13 21:00:18,850 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.34, Spatial_loss 1.50, Flat_loss 0.10, Train_acc 92.90, Test_acc 41.42
2024-09-13 21:00:27,775 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.32, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 93.89, Test_acc 40.00
2024-09-13 21:00:34,967 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.31, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 94.03, Test_acc 39.30
2024-09-13 21:00:44,287 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.32, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 93.71, Test_acc 40.53
2024-09-13 21:00:51,460 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.31, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 94.17, Test_acc 36.83
2024-09-13 21:01:00,720 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.31, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 94.19, Test_acc 41.50
2024-09-13 21:01:07,897 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.29, Spatial_loss 1.40, Flat_loss 0.10, Train_acc 94.73, Test_acc 41.50
2024-09-13 21:01:17,083 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.10, Train_acc 94.76, Test_acc 39.47
2024-09-13 21:01:24,190 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.09, Train_acc 95.09, Test_acc 41.68
2024-09-13 21:01:33,072 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.29, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 94.66, Test_acc 42.57
2024-09-13 21:01:40,338 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.09, Train_acc 95.37, Test_acc 40.12
2024-09-13 21:01:49,443 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.09, Train_acc 95.17, Test_acc 41.40
2024-09-13 21:01:56,559 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.09, Train_acc 94.99, Test_acc 40.27
2024-09-13 21:02:05,568 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 1.32, Flat_loss 0.09, Train_acc 95.57, Test_acc 41.33
2024-09-13 21:02:15,862 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.09, Train_acc 95.49, Test_acc 41.92
2024-09-13 21:02:25,498 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.09, Train_acc 95.67, Test_acc 42.20
2024-09-13 21:02:32,995 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 1.32, Flat_loss 0.09, Train_acc 96.16, Test_acc 41.20
2024-09-13 21:02:42,877 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.09, Train_acc 95.83, Test_acc 41.92
2024-09-13 21:02:50,018 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.09, Train_acc 96.40, Test_acc 41.17
2024-09-13 21:02:58,988 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.09, Train_acc 96.29, Test_acc 42.35
2024-09-13 21:03:06,134 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.24, Spatial_loss 1.22, Flat_loss 0.09, Train_acc 95.93, Test_acc 42.47
2024-09-13 21:03:15,109 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.09, Train_acc 96.24, Test_acc 40.15
2024-09-13 21:03:22,133 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.09, Train_acc 96.96, Test_acc 42.38
2024-09-13 21:03:30,790 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.09, Train_acc 96.59, Test_acc 41.10
2024-09-13 21:03:38,014 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.09, Train_acc 96.91, Test_acc 41.75
2024-09-13 21:03:46,954 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.09, Train_acc 96.87, Test_acc 43.28
2024-09-13 21:03:53,916 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.09, Train_acc 97.30, Test_acc 42.83
2024-09-13 21:04:02,793 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.09, Train_acc 97.13, Test_acc 42.77
2024-09-13 21:04:09,941 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.09, Train_acc 97.20, Test_acc 42.40
2024-09-13 21:04:18,979 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.09, Train_acc 97.40, Test_acc 42.55
2024-09-13 21:04:26,143 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 96.97, Test_acc 42.32
2024-09-13 21:04:35,124 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 97.14, Test_acc 42.83
2024-09-13 21:04:42,289 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 97.21, Test_acc 42.48
2024-09-13 21:04:51,236 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 97.00, Test_acc 42.38
2024-09-13 21:04:58,407 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.20, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 97.43, Test_acc 42.92
2024-09-13 21:05:08,986 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 97.56, Test_acc 42.27
2024-09-13 21:05:16,118 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 97.71, Test_acc 42.80
2024-09-13 21:05:24,477 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.08, Train_acc 97.41, Test_acc 42.95
2024-09-13 21:05:31,690 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 98.00, Test_acc 43.25
2024-09-13 21:05:40,681 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 97.63, Test_acc 42.78
2024-09-13 21:05:47,808 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.08, Train_acc 97.77, Test_acc 43.17
2024-09-13 21:05:56,911 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.08, Train_acc 98.03, Test_acc 42.77
2024-09-13 21:06:04,054 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.08, Train_acc 97.86, Test_acc 43.13
2024-09-13 21:06:13,182 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.08, Train_acc 98.00, Test_acc 42.95
2024-09-13 21:06:20,251 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.08, Train_acc 97.66, Test_acc 42.72
2024-09-13 21:06:29,148 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.08, Train_acc 97.93, Test_acc 42.90
2024-09-13 21:06:36,378 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.08, Train_acc 97.97, Test_acc 43.17
2024-09-13 21:06:45,479 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.08, Train_acc 98.11, Test_acc 43.30
2024-09-13 21:06:52,620 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.08, Train_acc 97.81, Test_acc 43.18
2024-09-13 21:07:01,967 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.08, Train_acc 98.09, Test_acc 43.18
2024-09-13 21:07:09,255 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.08, Train_acc 97.90, Test_acc 42.93
2024-09-13 21:07:18,440 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.01, Flat_loss 0.08, Train_acc 97.90, Test_acc 43.00
2024-09-13 21:07:25,685 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.08, Train_acc 98.11, Test_acc 43.02
2024-09-13 21:07:34,876 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.08, Train_acc 97.91, Test_acc 43.20
2024-09-13 21:07:42,224 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.08, Train_acc 98.19, Test_acc 43.25
2024-09-13 21:07:52,844 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.08, Train_acc 98.09, Test_acc 43.03
2024-09-13 21:08:03,127 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.08, Train_acc 98.09, Test_acc 42.93
2024-09-13 21:08:13,185 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.08, Train_acc 98.26, Test_acc 43.05
2024-09-13 21:08:20,591 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.08, Train_acc 98.09, Test_acc 43.18
2024-09-13 21:08:30,547 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.08, Train_acc 98.11, Test_acc 43.20
2024-09-13 21:08:30,548 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 21:08:30,549 [base.py] => Reducing exemplars...(40 per classes)
2024-09-13 21:08:42,390 [base.py] => Constructing exemplars...(40 per classes)
2024-09-13 21:08:48,857 [podnet.py] => The size of finetune dataset: 2400
2024-09-13 21:08:52,676 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.24, Spatial_loss 1.03, Flat_loss 0.05, Train_acc 96.67, Test_acc 45.85
2024-09-13 21:08:58,475 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.05, Train_acc 98.46, Test_acc 46.70
2024-09-13 21:09:02,424 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.05, Train_acc 99.00, Test_acc 46.58
2024-09-13 21:09:06,225 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.05, Train_acc 98.67, Test_acc 46.80
2024-09-13 21:09:11,203 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.16, Spatial_loss 1.03, Flat_loss 0.05, Train_acc 98.75, Test_acc 47.37
2024-09-13 21:09:16,212 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.05, Train_acc 98.42, Test_acc 47.43
2024-09-13 21:09:20,127 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.05, Train_acc 99.00, Test_acc 47.93
2024-09-13 21:09:24,069 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.05, Train_acc 98.75, Test_acc 47.98
2024-09-13 21:09:29,844 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.15, Spatial_loss 1.02, Flat_loss 0.05, Train_acc 98.58, Test_acc 47.90
2024-09-13 21:09:33,949 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 99.08, Test_acc 48.05
2024-09-13 21:09:38,053 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.05, Train_acc 99.46, Test_acc 48.67
2024-09-13 21:09:43,050 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 99.17, Test_acc 48.30
2024-09-13 21:09:48,216 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 99.08, Test_acc 48.52
2024-09-13 21:09:52,212 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 99.04, Test_acc 48.45
2024-09-13 21:09:56,212 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.05, Train_acc 98.79, Test_acc 48.42
2024-09-13 21:10:02,038 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.05, Train_acc 99.12, Test_acc 48.52
2024-09-13 21:10:06,057 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.05, Train_acc 99.21, Test_acc 48.48
2024-09-13 21:10:10,006 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 0.95, Flat_loss 0.05, Train_acc 99.17, Test_acc 48.67
2024-09-13 21:10:14,822 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.14, Spatial_loss 0.96, Flat_loss 0.05, Train_acc 98.79, Test_acc 48.43
2024-09-13 21:10:19,868 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.05, Train_acc 99.17, Test_acc 48.52
2024-09-13 21:10:19,870 [base.py] => Reducing exemplars...(33 per classes)
2024-09-13 21:10:31,597 [base.py] => Constructing exemplars...(33 per classes)
2024-09-13 21:10:45,044 [podnet.py] => Exemplar size: 1980
2024-09-13 21:10:45,044 [trainer.py] => CNN: {'total': 48.52, '00-09': 59.8, '10-19': 25.4, '20-29': 41.8, '30-39': 38.8, '40-49': 58.1, '50-59': 67.2, 'old': 44.78, 'new': 67.2}
2024-09-13 21:10:45,045 [trainer.py] => NME: {'total': 44.37, '00-09': 74.1, '10-19': 23.0, '20-29': 38.0, '30-39': 33.5, '40-49': 49.6, '50-59': 48.0, 'old': 43.64, 'new': 48.0}
2024-09-13 21:10:45,045 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23, 57.38, 53.36, 48.52]
2024-09-13 21:10:45,045 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67, 83.42, 80.74, 76.17]
2024-09-13 21:10:45,045 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53, 52.48, 49.36, 44.37]
2024-09-13 21:10:45,045 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23, 82.1, 80.28, 74.73]

2024-09-13 21:10:45,046 [trainer.py] => All params: 501905
2024-09-13 21:10:45,046 [trainer.py] => Trainable params: 501905
2024-09-13 21:10:45,048 [podnet.py] => Learning on 60-70
2024-09-13 21:10:45,136 [podnet.py] => Adaptive factor: 2.6457513110645907
2024-09-13 21:10:55,145 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 3.01, Spatial_loss 2.67, Flat_loss 0.20, Train_acc 43.95, Test_acc 24.23
2024-09-13 21:11:02,861 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 1.53, Spatial_loss 2.52, Flat_loss 0.15, Train_acc 59.47, Test_acc 26.03
2024-09-13 21:11:13,262 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 1.37, Spatial_loss 2.40, Flat_loss 0.14, Train_acc 64.03, Test_acc 34.51
2024-09-13 21:11:20,632 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 1.27, Spatial_loss 2.38, Flat_loss 0.14, Train_acc 66.00, Test_acc 27.93
2024-09-13 21:11:30,167 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 2.36, Flat_loss 0.14, Train_acc 67.69, Test_acc 25.91
2024-09-13 21:11:37,603 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 1.14, Spatial_loss 2.35, Flat_loss 0.14, Train_acc 69.86, Test_acc 31.37
2024-09-13 21:11:47,185 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 1.08, Spatial_loss 2.22, Flat_loss 0.13, Train_acc 71.52, Test_acc 31.50
2024-09-13 21:11:54,464 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 1.02, Spatial_loss 2.23, Flat_loss 0.13, Train_acc 72.95, Test_acc 28.89
2024-09-13 21:12:03,893 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 1.02, Spatial_loss 2.26, Flat_loss 0.13, Train_acc 72.42, Test_acc 34.17
2024-09-13 21:12:11,365 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.99, Spatial_loss 2.21, Flat_loss 0.13, Train_acc 73.77, Test_acc 24.61
2024-09-13 21:12:20,839 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.96, Spatial_loss 2.14, Flat_loss 0.13, Train_acc 74.74, Test_acc 33.90
2024-09-13 21:12:28,214 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.92, Spatial_loss 2.17, Flat_loss 0.13, Train_acc 75.90, Test_acc 31.93
2024-09-13 21:12:37,796 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.91, Spatial_loss 2.18, Flat_loss 0.13, Train_acc 75.99, Test_acc 29.07
2024-09-13 21:12:45,261 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.91, Spatial_loss 2.24, Flat_loss 0.13, Train_acc 75.79, Test_acc 33.09
2024-09-13 21:12:54,982 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.91, Spatial_loss 2.20, Flat_loss 0.13, Train_acc 75.76, Test_acc 31.90
2024-09-13 21:13:02,295 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.88, Spatial_loss 2.14, Flat_loss 0.13, Train_acc 76.83, Test_acc 33.70
2024-09-13 21:13:11,704 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.84, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 78.05, Test_acc 33.17
2024-09-13 21:13:19,014 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.81, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 78.78, Test_acc 33.63
2024-09-13 21:13:29,762 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.81, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 78.72, Test_acc 34.70
2024-09-13 21:13:37,404 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.83, Spatial_loss 2.13, Flat_loss 0.13, Train_acc 78.02, Test_acc 31.69
2024-09-13 21:13:47,609 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.82, Spatial_loss 2.06, Flat_loss 0.13, Train_acc 78.75, Test_acc 34.20
2024-09-13 21:13:54,992 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.79, Spatial_loss 2.15, Flat_loss 0.13, Train_acc 79.74, Test_acc 34.01
2024-09-13 21:14:04,587 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.80, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 78.84, Test_acc 31.87
2024-09-13 21:14:11,987 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.79, Spatial_loss 2.11, Flat_loss 0.13, Train_acc 79.37, Test_acc 34.59
2024-09-13 21:14:21,746 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.79, Spatial_loss 2.14, Flat_loss 0.13, Train_acc 79.79, Test_acc 35.56
2024-09-13 21:14:29,049 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.75, Spatial_loss 2.04, Flat_loss 0.13, Train_acc 81.13, Test_acc 34.47
2024-09-13 21:14:38,461 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.73, Spatial_loss 2.00, Flat_loss 0.13, Train_acc 81.52, Test_acc 32.99
2024-09-13 21:14:45,849 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.74, Spatial_loss 2.06, Flat_loss 0.13, Train_acc 80.76, Test_acc 31.97
2024-09-13 21:14:55,288 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.74, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 80.96, Test_acc 34.29
2024-09-13 21:15:02,518 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.75, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 80.49, Test_acc 35.81
2024-09-13 21:15:11,870 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.71, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 81.19, Test_acc 33.73
2024-09-13 21:15:19,235 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.70, Spatial_loss 1.99, Flat_loss 0.13, Train_acc 81.91, Test_acc 34.57
2024-09-13 21:15:28,714 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.69, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 82.31, Test_acc 33.69
2024-09-13 21:15:35,972 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.72, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 81.29, Test_acc 34.20
2024-09-13 21:15:45,453 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.71, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 82.08, Test_acc 33.07
2024-09-13 21:15:52,767 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.70, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 81.98, Test_acc 34.23
2024-09-13 21:16:02,378 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.68, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 82.94, Test_acc 34.84
2024-09-13 21:16:09,762 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.67, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 82.58, Test_acc 34.20
2024-09-13 21:16:20,427 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.67, Spatial_loss 2.00, Flat_loss 0.13, Train_acc 82.26, Test_acc 32.51
2024-09-13 21:16:27,777 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.67, Spatial_loss 2.04, Flat_loss 0.13, Train_acc 82.26, Test_acc 33.33
2024-09-13 21:16:37,304 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.66, Spatial_loss 2.07, Flat_loss 0.13, Train_acc 83.17, Test_acc 31.39
2024-09-13 21:16:44,768 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.66, Spatial_loss 2.06, Flat_loss 0.13, Train_acc 83.14, Test_acc 36.84
2024-09-13 21:16:54,410 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.64, Spatial_loss 1.99, Flat_loss 0.13, Train_acc 83.54, Test_acc 34.96
2024-09-13 21:17:01,660 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.63, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 83.98, Test_acc 31.70
2024-09-13 21:17:11,186 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.63, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 83.84, Test_acc 35.53
2024-09-13 21:17:18,612 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.63, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 84.28, Test_acc 34.37
2024-09-13 21:17:28,066 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.63, Spatial_loss 2.01, Flat_loss 0.13, Train_acc 84.68, Test_acc 31.19
2024-09-13 21:17:35,362 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.60, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 84.73, Test_acc 37.17
2024-09-13 21:17:44,792 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.59, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 85.07, Test_acc 33.94
2024-09-13 21:17:52,121 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.59, Spatial_loss 1.96, Flat_loss 0.13, Train_acc 85.21, Test_acc 33.60
2024-09-13 21:18:01,492 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.58, Spatial_loss 2.00, Flat_loss 0.13, Train_acc 85.67, Test_acc 35.13
2024-09-13 21:18:08,842 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.59, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 85.07, Test_acc 34.06
2024-09-13 21:18:18,123 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.61, Spatial_loss 1.96, Flat_loss 0.13, Train_acc 84.07, Test_acc 31.69
2024-09-13 21:18:25,305 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.58, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 85.70, Test_acc 36.51
2024-09-13 21:18:34,547 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.58, Spatial_loss 1.90, Flat_loss 0.13, Train_acc 85.76, Test_acc 32.01
2024-09-13 21:18:41,848 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.58, Spatial_loss 1.92, Flat_loss 0.13, Train_acc 85.54, Test_acc 34.04
2024-09-13 21:18:51,255 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.57, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 85.85, Test_acc 34.17
2024-09-13 21:19:00,022 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.58, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 85.76, Test_acc 36.33
2024-09-13 21:19:10,234 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.55, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 86.70, Test_acc 33.24
2024-09-13 21:19:17,676 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.53, Spatial_loss 1.92, Flat_loss 0.13, Train_acc 87.31, Test_acc 35.31
2024-09-13 21:19:27,050 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.54, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 86.86, Test_acc 35.54
2024-09-13 21:19:34,262 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.53, Spatial_loss 1.85, Flat_loss 0.13, Train_acc 87.51, Test_acc 34.33
2024-09-13 21:19:43,654 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.53, Spatial_loss 1.91, Flat_loss 0.13, Train_acc 87.09, Test_acc 37.77
2024-09-13 21:19:51,103 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.52, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 87.59, Test_acc 35.20
2024-09-13 21:20:00,501 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.52, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 87.44, Test_acc 33.79
2024-09-13 21:20:07,753 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.51, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 87.55, Test_acc 37.10
2024-09-13 21:20:17,108 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.51, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 88.52, Test_acc 36.06
2024-09-13 21:20:24,539 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.50, Spatial_loss 1.83, Flat_loss 0.12, Train_acc 88.21, Test_acc 34.14
2024-09-13 21:20:34,130 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.49, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 88.58, Test_acc 35.51
2024-09-13 21:20:41,459 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.51, Spatial_loss 1.89, Flat_loss 0.13, Train_acc 88.02, Test_acc 36.61
2024-09-13 21:20:50,692 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.47, Spatial_loss 1.82, Flat_loss 0.12, Train_acc 89.21, Test_acc 35.04
2024-09-13 21:20:57,912 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.46, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 89.63, Test_acc 38.43
2024-09-13 21:21:07,098 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.47, Spatial_loss 1.80, Flat_loss 0.12, Train_acc 89.24, Test_acc 35.54
2024-09-13 21:21:14,418 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.47, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 88.84, Test_acc 34.61
2024-09-13 21:21:23,745 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.45, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 89.80, Test_acc 36.19
2024-09-13 21:21:30,988 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.43, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 90.17, Test_acc 35.03
2024-09-13 21:21:40,666 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.43, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 90.19, Test_acc 37.93
2024-09-13 21:21:52,091 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.44, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 89.89, Test_acc 35.70
2024-09-13 21:22:01,278 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.45, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 89.24, Test_acc 37.26
2024-09-13 21:22:09,179 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.42, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 90.60, Test_acc 35.07
2024-09-13 21:22:19,139 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.42, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 90.72, Test_acc 38.41
2024-09-13 21:22:26,570 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.40, Spatial_loss 1.68, Flat_loss 0.12, Train_acc 91.38, Test_acc 37.00
2024-09-13 21:22:36,642 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.40, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 91.36, Test_acc 35.53
2024-09-13 21:22:43,885 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.12, Train_acc 91.33, Test_acc 37.84
2024-09-13 21:22:53,191 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.12, Train_acc 91.33, Test_acc 36.10
2024-09-13 21:23:00,482 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.41, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 90.76, Test_acc 35.89
2024-09-13 21:23:09,836 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.40, Spatial_loss 1.66, Flat_loss 0.12, Train_acc 91.15, Test_acc 36.00
2024-09-13 21:23:17,061 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.38, Spatial_loss 1.66, Flat_loss 0.12, Train_acc 91.76, Test_acc 35.87
2024-09-13 21:23:26,316 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.36, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 92.52, Test_acc 37.26
2024-09-13 21:23:33,695 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.37, Spatial_loss 1.64, Flat_loss 0.12, Train_acc 92.78, Test_acc 37.96
2024-09-13 21:23:43,536 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.37, Spatial_loss 1.69, Flat_loss 0.12, Train_acc 92.26, Test_acc 36.77
2024-09-13 21:23:50,836 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.37, Spatial_loss 1.61, Flat_loss 0.12, Train_acc 92.28, Test_acc 37.94
2024-09-13 21:24:00,616 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.35, Spatial_loss 1.64, Flat_loss 0.11, Train_acc 92.61, Test_acc 36.70
2024-09-13 21:24:07,926 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.35, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 93.02, Test_acc 36.94
2024-09-13 21:24:17,416 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.34, Spatial_loss 1.55, Flat_loss 0.11, Train_acc 93.37, Test_acc 36.63
2024-09-13 21:24:24,931 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.34, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 93.34, Test_acc 36.53
2024-09-13 21:24:35,654 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.33, Spatial_loss 1.54, Flat_loss 0.11, Train_acc 93.48, Test_acc 37.14
2024-09-13 21:24:42,998 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.51, Flat_loss 0.11, Train_acc 93.98, Test_acc 38.37
2024-09-13 21:24:52,957 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.30, Spatial_loss 1.52, Flat_loss 0.11, Train_acc 94.44, Test_acc 37.90
2024-09-13 21:25:00,236 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.32, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 94.18, Test_acc 39.07
2024-09-13 21:25:09,885 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.31, Spatial_loss 1.49, Flat_loss 0.11, Train_acc 94.30, Test_acc 38.74
2024-09-13 21:25:17,213 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 94.41, Test_acc 37.01
2024-09-13 21:25:27,067 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.29, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 94.53, Test_acc 37.86
2024-09-13 21:25:34,573 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.29, Spatial_loss 1.48, Flat_loss 0.11, Train_acc 94.76, Test_acc 38.57
2024-09-13 21:25:44,220 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.29, Spatial_loss 1.47, Flat_loss 0.11, Train_acc 94.60, Test_acc 36.70
2024-09-13 21:25:51,564 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.29, Spatial_loss 1.45, Flat_loss 0.11, Train_acc 95.03, Test_acc 37.81
2024-09-13 21:26:01,051 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.29, Spatial_loss 1.46, Flat_loss 0.11, Train_acc 94.87, Test_acc 37.51
2024-09-13 21:26:08,461 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.28, Spatial_loss 1.43, Flat_loss 0.11, Train_acc 95.21, Test_acc 38.09
2024-09-13 21:26:17,953 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.11, Train_acc 95.16, Test_acc 37.20
2024-09-13 21:26:25,439 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.28, Spatial_loss 1.39, Flat_loss 0.11, Train_acc 95.16, Test_acc 38.17
2024-09-13 21:26:34,889 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.27, Spatial_loss 1.42, Flat_loss 0.11, Train_acc 95.47, Test_acc 38.19
2024-09-13 21:26:42,203 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.26, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 96.00, Test_acc 39.19
2024-09-13 21:26:51,589 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.26, Spatial_loss 1.36, Flat_loss 0.10, Train_acc 96.02, Test_acc 38.67
2024-09-13 21:26:58,974 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.25, Spatial_loss 1.32, Flat_loss 0.10, Train_acc 96.35, Test_acc 38.67
2024-09-13 21:27:08,871 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.26, Spatial_loss 1.38, Flat_loss 0.10, Train_acc 95.76, Test_acc 38.61
2024-09-13 21:27:20,351 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.33, Flat_loss 0.10, Train_acc 96.17, Test_acc 38.74
2024-09-13 21:27:27,998 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 1.34, Flat_loss 0.10, Train_acc 96.19, Test_acc 38.96
2024-09-13 21:27:37,449 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.24, Spatial_loss 1.31, Flat_loss 0.10, Train_acc 96.58, Test_acc 37.29
2024-09-13 21:27:44,832 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.10, Train_acc 96.78, Test_acc 37.01
2024-09-13 21:27:53,324 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.23, Spatial_loss 1.32, Flat_loss 0.10, Train_acc 96.79, Test_acc 38.29
2024-09-13 21:28:00,754 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 1.27, Flat_loss 0.10, Train_acc 97.13, Test_acc 38.93
2024-09-13 21:28:10,137 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 1.26, Flat_loss 0.10, Train_acc 96.93, Test_acc 37.94
2024-09-13 21:28:17,511 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 1.26, Flat_loss 0.10, Train_acc 97.18, Test_acc 38.36
2024-09-13 21:28:27,305 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 1.25, Flat_loss 0.10, Train_acc 97.23, Test_acc 38.66
2024-09-13 21:28:34,580 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 1.21, Flat_loss 0.10, Train_acc 97.09, Test_acc 38.37
2024-09-13 21:28:43,932 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.22, Spatial_loss 1.24, Flat_loss 0.10, Train_acc 97.42, Test_acc 38.70
2024-09-13 21:28:51,195 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.22, Spatial_loss 1.21, Flat_loss 0.10, Train_acc 97.32, Test_acc 38.96
2024-09-13 21:29:00,582 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.21, Spatial_loss 1.24, Flat_loss 0.10, Train_acc 97.69, Test_acc 38.09
2024-09-13 21:29:07,889 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.10, Train_acc 97.28, Test_acc 38.03
2024-09-13 21:29:17,222 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.10, Train_acc 97.45, Test_acc 38.03
2024-09-13 21:29:24,512 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.10, Train_acc 97.64, Test_acc 37.43
2024-09-13 21:29:33,703 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.10, Train_acc 97.62, Test_acc 38.90
2024-09-13 21:29:40,975 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 97.66, Test_acc 38.81
2024-09-13 21:29:51,711 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.10, Train_acc 97.72, Test_acc 39.13
2024-09-13 21:29:59,571 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.09, Train_acc 98.02, Test_acc 39.40
2024-09-13 21:30:09,504 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 98.05, Test_acc 38.40
2024-09-13 21:30:16,756 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 98.12, Test_acc 39.33
2024-09-13 21:30:25,940 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 98.09, Test_acc 38.99
2024-09-13 21:30:33,353 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 98.12, Test_acc 39.19
2024-09-13 21:30:42,521 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.09, Train_acc 98.22, Test_acc 39.23
2024-09-13 21:30:49,819 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 98.17, Test_acc 39.29
2024-09-13 21:30:59,228 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.09, Train_acc 98.41, Test_acc 38.77
2024-09-13 21:31:06,358 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.09, Train_acc 98.04, Test_acc 39.41
2024-09-13 21:31:15,649 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.09, Train_acc 98.19, Test_acc 39.09
2024-09-13 21:31:22,875 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 98.40, Test_acc 38.80
2024-09-13 21:31:32,063 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.09, Train_acc 98.35, Test_acc 39.09
2024-09-13 21:31:39,282 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.38, Test_acc 39.21
2024-09-13 21:31:48,418 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.41, Test_acc 38.86
2024-09-13 21:31:55,754 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.25, Test_acc 39.29
2024-09-13 21:32:04,856 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.51, Test_acc 39.60
2024-09-13 21:32:12,102 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.30, Test_acc 39.06
2024-09-13 21:32:21,351 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.64, Test_acc 39.21
2024-09-13 21:32:30,082 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.09, Train_acc 98.31, Test_acc 39.27
2024-09-13 21:32:40,361 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.09, Train_acc 98.32, Test_acc 39.11
2024-09-13 21:32:47,593 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 98.55, Test_acc 39.36
2024-09-13 21:32:56,846 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 98.55, Test_acc 39.31
2024-09-13 21:33:04,258 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.09, Train_acc 98.55, Test_acc 39.30
2024-09-13 21:33:13,524 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.09, Train_acc 98.52, Test_acc 39.20
2024-09-13 21:33:20,859 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.09, Train_acc 98.52, Test_acc 39.19
2024-09-13 21:33:30,198 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.09, Train_acc 98.21, Test_acc 39.24
2024-09-13 21:33:30,199 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 21:33:30,200 [base.py] => Reducing exemplars...(33 per classes)
2024-09-13 21:33:44,097 [base.py] => Constructing exemplars...(33 per classes)
2024-09-13 21:33:50,315 [podnet.py] => The size of finetune dataset: 2310
2024-09-13 21:33:55,838 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.35, Spatial_loss 1.20, Flat_loss 0.06, Train_acc 95.37, Test_acc 42.79
2024-09-13 21:34:00,066 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.30, Spatial_loss 1.28, Flat_loss 0.07, Train_acc 96.49, Test_acc 43.10
2024-09-13 21:34:04,233 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.06, Train_acc 96.84, Test_acc 43.44
2024-09-13 21:34:09,387 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.29, Spatial_loss 1.25, Flat_loss 0.07, Train_acc 97.10, Test_acc 43.53
2024-09-13 21:34:14,548 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.31, Spatial_loss 1.28, Flat_loss 0.07, Train_acc 97.23, Test_acc 43.23
2024-09-13 21:34:18,632 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.26, Spatial_loss 1.27, Flat_loss 0.07, Train_acc 97.10, Test_acc 43.53
2024-09-13 21:34:22,649 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.30, Spatial_loss 1.28, Flat_loss 0.07, Train_acc 97.75, Test_acc 44.19
2024-09-13 21:34:28,706 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.27, Spatial_loss 1.22, Flat_loss 0.07, Train_acc 97.49, Test_acc 44.66
2024-09-13 21:34:32,979 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.25, Spatial_loss 1.25, Flat_loss 0.07, Train_acc 97.84, Test_acc 43.70
2024-09-13 21:34:37,020 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.25, Spatial_loss 1.20, Flat_loss 0.06, Train_acc 97.92, Test_acc 44.96
2024-09-13 21:34:42,131 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.20, Spatial_loss 1.21, Flat_loss 0.06, Train_acc 98.18, Test_acc 45.11
2024-09-13 21:34:46,844 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.24, Spatial_loss 1.14, Flat_loss 0.06, Train_acc 98.70, Test_acc 45.31
2024-09-13 21:34:50,837 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.06, Train_acc 97.84, Test_acc 45.16
2024-09-13 21:34:55,539 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.06, Train_acc 98.57, Test_acc 45.36
2024-09-13 21:35:00,558 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.23, Spatial_loss 1.18, Flat_loss 0.07, Train_acc 98.66, Test_acc 45.49
2024-09-13 21:35:05,004 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.19, Spatial_loss 1.13, Flat_loss 0.06, Train_acc 99.31, Test_acc 45.33
2024-09-13 21:35:10,730 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.06, Train_acc 98.66, Test_acc 45.67
2024-09-13 21:35:15,814 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.27, Spatial_loss 1.17, Flat_loss 0.06, Train_acc 98.57, Test_acc 45.87
2024-09-13 21:35:19,808 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.06, Train_acc 99.05, Test_acc 45.93
2024-09-13 21:35:23,873 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.25, Spatial_loss 1.08, Flat_loss 0.06, Train_acc 98.61, Test_acc 46.00
2024-09-13 21:35:23,875 [base.py] => Reducing exemplars...(28 per classes)
2024-09-13 21:35:37,670 [base.py] => Constructing exemplars...(28 per classes)
2024-09-13 21:35:49,310 [podnet.py] => Exemplar size: 1960
2024-09-13 21:35:49,310 [trainer.py] => CNN: {'total': 46.0, '00-09': 56.3, '10-19': 21.4, '20-29': 38.9, '30-39': 34.1, '40-49': 52.4, '50-59': 47.7, '60-69': 71.2, 'old': 41.8, 'new': 71.2}
2024-09-13 21:35:49,310 [trainer.py] => NME: {'total': 41.6, '00-09': 71.6, '10-19': 20.2, '20-29': 35.8, '30-39': 28.6, '40-49': 41.8, '50-59': 32.5, '60-69': 60.7, 'old': 38.42, 'new': 60.7}
2024-09-13 21:35:49,311 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23, 57.38, 53.36, 48.52, 46.0]
2024-09-13 21:35:49,311 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67, 83.42, 80.74, 76.17, 73.29]
2024-09-13 21:35:49,311 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53, 52.48, 49.36, 44.37, 41.6]
2024-09-13 21:35:49,311 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23, 82.1, 80.28, 74.73, 71.44]

2024-09-13 21:35:49,312 [trainer.py] => All params: 508305
2024-09-13 21:35:49,312 [trainer.py] => Trainable params: 508305
2024-09-13 21:35:49,313 [podnet.py] => Learning on 70-80
2024-09-13 21:35:49,367 [podnet.py] => Adaptive factor: 2.8284271247461903
2024-09-13 21:35:58,190 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 2.97, Spatial_loss 2.79, Flat_loss 0.22, Train_acc 44.48, Test_acc 21.35
2024-09-13 21:36:05,763 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 1.57, Spatial_loss 2.77, Flat_loss 0.17, Train_acc 57.86, Test_acc 22.70
2024-09-13 21:36:15,717 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 1.40, Spatial_loss 2.72, Flat_loss 0.15, Train_acc 62.04, Test_acc 25.38
2024-09-13 21:36:23,217 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 1.32, Spatial_loss 2.56, Flat_loss 0.15, Train_acc 64.04, Test_acc 25.58
2024-09-13 21:36:33,275 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 1.25, Spatial_loss 2.48, Flat_loss 0.14, Train_acc 64.90, Test_acc 28.88
2024-09-13 21:36:40,745 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 1.18, Spatial_loss 2.40, Flat_loss 0.13, Train_acc 66.98, Test_acc 29.62
2024-09-13 21:36:50,892 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 1.13, Spatial_loss 2.51, Flat_loss 0.13, Train_acc 68.69, Test_acc 27.28
2024-09-13 21:36:58,557 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 1.11, Spatial_loss 2.37, Flat_loss 0.13, Train_acc 68.69, Test_acc 28.14
2024-09-13 21:37:08,887 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 1.07, Spatial_loss 2.43, Flat_loss 0.13, Train_acc 70.32, Test_acc 26.82
2024-09-13 21:37:16,468 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 1.05, Spatial_loss 2.34, Flat_loss 0.13, Train_acc 70.66, Test_acc 28.60
2024-09-13 21:37:26,782 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 1.04, Spatial_loss 2.34, Flat_loss 0.13, Train_acc 70.91, Test_acc 26.79
2024-09-13 21:37:34,522 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 1.03, Spatial_loss 2.30, Flat_loss 0.13, Train_acc 71.55, Test_acc 28.29
2024-09-13 21:37:46,595 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 1.00, Spatial_loss 2.29, Flat_loss 0.13, Train_acc 72.21, Test_acc 26.89
2024-09-13 21:37:54,829 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.99, Spatial_loss 2.29, Flat_loss 0.13, Train_acc 72.70, Test_acc 31.08
2024-09-13 21:38:05,298 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.98, Spatial_loss 2.27, Flat_loss 0.13, Train_acc 73.18, Test_acc 30.05
2024-09-13 21:38:13,059 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.95, Spatial_loss 2.24, Flat_loss 0.12, Train_acc 73.86, Test_acc 30.55
2024-09-13 21:38:23,600 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.96, Spatial_loss 2.31, Flat_loss 0.13, Train_acc 72.92, Test_acc 28.86
2024-09-13 21:38:31,114 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.95, Spatial_loss 2.35, Flat_loss 0.13, Train_acc 73.71, Test_acc 27.80
2024-09-13 21:38:41,188 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.91, Spatial_loss 2.17, Flat_loss 0.12, Train_acc 74.73, Test_acc 25.96
2024-09-13 21:38:48,797 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.91, Spatial_loss 2.28, Flat_loss 0.12, Train_acc 75.01, Test_acc 24.22
2024-09-13 21:38:58,928 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.90, Spatial_loss 2.31, Flat_loss 0.13, Train_acc 75.39, Test_acc 30.20
2024-09-13 21:39:06,646 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.90, Spatial_loss 2.28, Flat_loss 0.12, Train_acc 75.07, Test_acc 28.82
2024-09-13 21:39:16,730 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.87, Spatial_loss 2.22, Flat_loss 0.12, Train_acc 77.00, Test_acc 29.22
2024-09-13 21:39:24,380 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.89, Spatial_loss 2.23, Flat_loss 0.13, Train_acc 76.61, Test_acc 27.79
2024-09-13 21:39:34,561 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.87, Spatial_loss 2.22, Flat_loss 0.12, Train_acc 76.47, Test_acc 31.01
2024-09-13 21:39:42,268 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.87, Spatial_loss 2.20, Flat_loss 0.13, Train_acc 76.32, Test_acc 28.20
2024-09-13 21:39:52,465 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.84, Spatial_loss 2.13, Flat_loss 0.12, Train_acc 77.26, Test_acc 28.85
2024-09-13 21:40:00,066 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.84, Spatial_loss 2.18, Flat_loss 0.12, Train_acc 76.94, Test_acc 28.89
2024-09-13 21:40:10,233 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.84, Spatial_loss 2.18, Flat_loss 0.12, Train_acc 77.27, Test_acc 31.08
2024-09-13 21:40:19,331 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.82, Spatial_loss 2.19, Flat_loss 0.13, Train_acc 77.43, Test_acc 29.00
2024-09-13 21:40:30,036 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.84, Spatial_loss 2.14, Flat_loss 0.12, Train_acc 77.01, Test_acc 29.28
2024-09-13 21:40:37,756 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.82, Spatial_loss 2.18, Flat_loss 0.13, Train_acc 77.47, Test_acc 28.21
2024-09-13 21:40:47,931 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.80, Spatial_loss 2.17, Flat_loss 0.13, Train_acc 78.32, Test_acc 31.92
2024-09-13 21:40:55,528 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.80, Spatial_loss 2.19, Flat_loss 0.12, Train_acc 78.48, Test_acc 29.35
2024-09-13 21:41:05,563 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.80, Spatial_loss 2.18, Flat_loss 0.13, Train_acc 77.96, Test_acc 30.75
2024-09-13 21:41:13,263 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.79, Spatial_loss 2.08, Flat_loss 0.12, Train_acc 78.55, Test_acc 27.40
2024-09-13 21:41:23,284 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.79, Spatial_loss 2.21, Flat_loss 0.13, Train_acc 78.91, Test_acc 30.12
2024-09-13 21:41:30,807 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.77, Spatial_loss 2.14, Flat_loss 0.12, Train_acc 79.22, Test_acc 27.44
2024-09-13 21:41:40,879 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.76, Spatial_loss 2.16, Flat_loss 0.12, Train_acc 79.81, Test_acc 27.56
2024-09-13 21:41:48,546 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.78, Spatial_loss 2.13, Flat_loss 0.13, Train_acc 78.58, Test_acc 31.01
2024-09-13 21:41:58,794 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.76, Spatial_loss 2.11, Flat_loss 0.12, Train_acc 80.16, Test_acc 28.72
2024-09-13 21:42:06,429 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.76, Spatial_loss 2.22, Flat_loss 0.13, Train_acc 79.30, Test_acc 29.81
2024-09-13 21:42:16,269 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.74, Spatial_loss 2.19, Flat_loss 0.13, Train_acc 79.83, Test_acc 27.00
2024-09-13 21:42:23,747 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.75, Spatial_loss 2.08, Flat_loss 0.13, Train_acc 79.97, Test_acc 28.06
2024-09-13 21:42:33,362 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.73, Spatial_loss 2.09, Flat_loss 0.12, Train_acc 80.59, Test_acc 28.89
2024-09-13 21:42:41,045 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.74, Spatial_loss 2.13, Flat_loss 0.12, Train_acc 80.10, Test_acc 29.86
2024-09-13 21:42:51,582 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.73, Spatial_loss 2.15, Flat_loss 0.12, Train_acc 80.96, Test_acc 29.76
2024-09-13 21:43:03,535 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.73, Spatial_loss 2.10, Flat_loss 0.13, Train_acc 80.60, Test_acc 29.94
2024-09-13 21:43:11,453 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.72, Spatial_loss 2.12, Flat_loss 0.13, Train_acc 80.99, Test_acc 27.52
2024-09-13 21:43:20,308 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.71, Spatial_loss 2.14, Flat_loss 0.12, Train_acc 82.05, Test_acc 30.45
2024-09-13 21:43:27,841 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.72, Spatial_loss 2.14, Flat_loss 0.13, Train_acc 81.93, Test_acc 30.11
2024-09-13 21:43:37,885 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.70, Spatial_loss 2.09, Flat_loss 0.12, Train_acc 81.41, Test_acc 27.60
2024-09-13 21:43:45,564 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.69, Spatial_loss 2.07, Flat_loss 0.12, Train_acc 82.39, Test_acc 30.56
2024-09-13 21:43:55,763 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.68, Spatial_loss 2.04, Flat_loss 0.12, Train_acc 82.34, Test_acc 27.91
2024-09-13 21:44:03,319 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.67, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 82.14, Test_acc 27.56
2024-09-13 21:44:13,482 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.70, Spatial_loss 2.09, Flat_loss 0.13, Train_acc 81.26, Test_acc 27.36
2024-09-13 21:44:21,048 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.67, Spatial_loss 2.06, Flat_loss 0.12, Train_acc 82.34, Test_acc 30.02
2024-09-13 21:44:31,151 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.65, Spatial_loss 2.04, Flat_loss 0.12, Train_acc 83.29, Test_acc 32.59
2024-09-13 21:44:38,721 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.66, Spatial_loss 2.12, Flat_loss 0.12, Train_acc 82.87, Test_acc 31.95
2024-09-13 21:44:48,981 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.65, Spatial_loss 2.06, Flat_loss 0.12, Train_acc 82.66, Test_acc 29.82
2024-09-13 21:44:56,559 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.62, Spatial_loss 1.99, Flat_loss 0.12, Train_acc 83.86, Test_acc 25.91
2024-09-13 21:45:06,662 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.61, Spatial_loss 1.99, Flat_loss 0.12, Train_acc 84.37, Test_acc 31.21
2024-09-13 21:45:14,213 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.63, Spatial_loss 1.93, Flat_loss 0.12, Train_acc 83.86, Test_acc 29.76
2024-09-13 21:45:24,275 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.63, Spatial_loss 2.03, Flat_loss 0.12, Train_acc 84.50, Test_acc 30.45
2024-09-13 21:45:35,973 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.60, Spatial_loss 1.95, Flat_loss 0.12, Train_acc 84.94, Test_acc 31.12
2024-09-13 21:45:44,162 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.62, Spatial_loss 1.99, Flat_loss 0.12, Train_acc 84.17, Test_acc 29.31
2024-09-13 21:45:54,267 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.61, Spatial_loss 1.96, Flat_loss 0.12, Train_acc 84.51, Test_acc 32.65
2024-09-13 21:46:01,984 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.59, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 85.00, Test_acc 30.10
2024-09-13 21:46:10,944 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.58, Spatial_loss 1.94, Flat_loss 0.12, Train_acc 85.55, Test_acc 31.79
2024-09-13 21:46:18,675 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.58, Spatial_loss 1.91, Flat_loss 0.12, Train_acc 85.20, Test_acc 31.04
2024-09-13 21:46:28,819 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.57, Spatial_loss 1.92, Flat_loss 0.12, Train_acc 85.56, Test_acc 26.84
2024-09-13 21:46:36,375 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.58, Spatial_loss 1.95, Flat_loss 0.12, Train_acc 85.57, Test_acc 30.21
2024-09-13 21:46:46,515 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.57, Spatial_loss 1.98, Flat_loss 0.12, Train_acc 85.50, Test_acc 34.46
2024-09-13 21:46:54,082 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.56, Spatial_loss 1.89, Flat_loss 0.12, Train_acc 86.44, Test_acc 31.89
2024-09-13 21:47:04,430 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.55, Spatial_loss 1.89, Flat_loss 0.12, Train_acc 86.31, Test_acc 32.56
2024-09-13 21:47:12,012 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.56, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 86.54, Test_acc 31.80
2024-09-13 21:47:22,182 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.54, Spatial_loss 1.85, Flat_loss 0.12, Train_acc 86.72, Test_acc 31.62
2024-09-13 21:47:29,753 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.53, Spatial_loss 1.88, Flat_loss 0.12, Train_acc 87.11, Test_acc 33.41
2024-09-13 21:47:39,983 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.51, Spatial_loss 1.88, Flat_loss 0.11, Train_acc 87.90, Test_acc 30.35
2024-09-13 21:47:47,813 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.52, Spatial_loss 1.90, Flat_loss 0.12, Train_acc 87.14, Test_acc 32.36
2024-09-13 21:47:59,455 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.52, Spatial_loss 1.80, Flat_loss 0.11, Train_acc 87.21, Test_acc 32.75
2024-09-13 21:48:11,451 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.51, Spatial_loss 1.83, Flat_loss 0.11, Train_acc 87.28, Test_acc 32.26
2024-09-13 21:48:19,262 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 87.77, Test_acc 30.95
2024-09-13 21:48:28,042 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.49, Spatial_loss 1.83, Flat_loss 0.11, Train_acc 88.64, Test_acc 29.29
2024-09-13 21:48:35,686 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.49, Spatial_loss 1.81, Flat_loss 0.11, Train_acc 88.58, Test_acc 31.65
2024-09-13 21:48:45,840 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.49, Spatial_loss 1.76, Flat_loss 0.11, Train_acc 88.65, Test_acc 32.11
2024-09-13 21:48:53,462 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.49, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 88.46, Test_acc 31.42
2024-09-13 21:49:03,639 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.46, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 89.63, Test_acc 32.12
2024-09-13 21:49:11,318 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.45, Spatial_loss 1.81, Flat_loss 0.11, Train_acc 89.73, Test_acc 31.75
2024-09-13 21:49:21,289 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.46, Spatial_loss 1.74, Flat_loss 0.11, Train_acc 89.53, Test_acc 32.79
2024-09-13 21:49:28,712 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.45, Spatial_loss 1.77, Flat_loss 0.11, Train_acc 89.48, Test_acc 32.59
2024-09-13 21:49:38,321 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.43, Spatial_loss 1.75, Flat_loss 0.11, Train_acc 90.85, Test_acc 33.06
2024-09-13 21:49:45,828 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.43, Spatial_loss 1.72, Flat_loss 0.11, Train_acc 90.19, Test_acc 32.52
2024-09-13 21:49:55,758 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.45, Spatial_loss 1.70, Flat_loss 0.11, Train_acc 90.00, Test_acc 31.38
2024-09-13 21:50:03,191 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.42, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 90.42, Test_acc 29.12
2024-09-13 21:50:12,901 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.42, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 90.93, Test_acc 32.34
2024-09-13 21:50:20,541 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.40, Spatial_loss 1.66, Flat_loss 0.11, Train_acc 91.55, Test_acc 34.26
2024-09-13 21:50:32,012 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.40, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 91.19, Test_acc 32.48
2024-09-13 21:50:40,767 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.40, Spatial_loss 1.71, Flat_loss 0.11, Train_acc 91.75, Test_acc 32.39
2024-09-13 21:50:50,995 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.39, Spatial_loss 1.65, Flat_loss 0.11, Train_acc 91.97, Test_acc 31.52
2024-09-13 21:50:58,760 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.39, Spatial_loss 1.61, Flat_loss 0.11, Train_acc 92.00, Test_acc 34.01
2024-09-13 21:51:09,206 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.37, Spatial_loss 1.55, Flat_loss 0.10, Train_acc 92.60, Test_acc 30.22
2024-09-13 21:51:16,685 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.38, Spatial_loss 1.56, Flat_loss 0.10, Train_acc 92.08, Test_acc 31.61
2024-09-13 21:51:26,692 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.37, Spatial_loss 1.60, Flat_loss 0.10, Train_acc 92.33, Test_acc 32.24
2024-09-13 21:51:34,175 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.37, Spatial_loss 1.56, Flat_loss 0.10, Train_acc 92.40, Test_acc 34.40
2024-09-13 21:51:43,987 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.36, Spatial_loss 1.52, Flat_loss 0.10, Train_acc 92.70, Test_acc 33.10
2024-09-13 21:51:51,652 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.36, Spatial_loss 1.55, Flat_loss 0.10, Train_acc 93.03, Test_acc 32.96
2024-09-13 21:52:01,652 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.10, Train_acc 93.10, Test_acc 32.09
2024-09-13 21:52:09,080 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 93.29, Test_acc 31.50
2024-09-13 21:52:19,034 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.34, Spatial_loss 1.52, Flat_loss 0.10, Train_acc 93.51, Test_acc 32.90
2024-09-13 21:52:26,448 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.33, Spatial_loss 1.41, Flat_loss 0.10, Train_acc 93.94, Test_acc 33.09
2024-09-13 21:52:36,160 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.33, Spatial_loss 1.49, Flat_loss 0.10, Train_acc 93.69, Test_acc 31.55
2024-09-13 21:52:43,600 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 93.91, Test_acc 33.72
2024-09-13 21:52:53,285 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.10, Train_acc 93.91, Test_acc 33.09
2024-09-13 21:53:00,787 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.10, Train_acc 93.68, Test_acc 32.81
2024-09-13 21:53:11,525 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.31, Spatial_loss 1.50, Flat_loss 0.10, Train_acc 94.12, Test_acc 33.76
2024-09-13 21:53:19,042 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.31, Spatial_loss 1.43, Flat_loss 0.10, Train_acc 94.67, Test_acc 33.91
2024-09-13 21:53:28,921 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.31, Spatial_loss 1.39, Flat_loss 0.10, Train_acc 94.21, Test_acc 34.35
2024-09-13 21:53:36,412 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.30, Spatial_loss 1.40, Flat_loss 0.10, Train_acc 94.90, Test_acc 33.79
2024-09-13 21:53:46,458 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.10, Train_acc 95.16, Test_acc 33.14
2024-09-13 21:53:54,074 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.10, Train_acc 95.33, Test_acc 33.91
2024-09-13 21:54:04,192 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.09, Train_acc 95.46, Test_acc 33.35
2024-09-13 21:54:11,677 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.09, Train_acc 95.22, Test_acc 33.41
2024-09-13 21:54:21,850 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.09, Train_acc 95.43, Test_acc 33.95
2024-09-13 21:54:29,298 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.28, Spatial_loss 1.35, Flat_loss 0.09, Train_acc 95.45, Test_acc 32.83
2024-09-13 21:54:39,260 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.09, Train_acc 95.80, Test_acc 34.38
2024-09-13 21:54:46,735 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.09, Train_acc 95.89, Test_acc 33.86
2024-09-13 21:54:56,676 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.09, Train_acc 95.82, Test_acc 33.35
2024-09-13 21:55:04,096 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.27, Spatial_loss 1.29, Flat_loss 0.09, Train_acc 95.73, Test_acc 33.40
2024-09-13 21:55:13,818 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.27, Spatial_loss 1.27, Flat_loss 0.09, Train_acc 96.08, Test_acc 34.02
2024-09-13 21:55:21,266 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.09, Train_acc 96.09, Test_acc 33.81
2024-09-13 21:55:31,232 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.26, Spatial_loss 1.26, Flat_loss 0.09, Train_acc 96.42, Test_acc 33.67
2024-09-13 21:55:42,775 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.26, Spatial_loss 1.25, Flat_loss 0.09, Train_acc 96.08, Test_acc 34.06
2024-09-13 21:55:50,346 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.09, Train_acc 96.80, Test_acc 34.20
2024-09-13 21:55:59,496 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.26, Spatial_loss 1.22, Flat_loss 0.09, Train_acc 96.15, Test_acc 33.64
2024-09-13 21:56:06,990 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.09, Train_acc 96.41, Test_acc 34.28
2024-09-13 21:56:16,564 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.25, Spatial_loss 1.21, Flat_loss 0.09, Train_acc 96.49, Test_acc 34.00
2024-09-13 21:56:24,213 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.09, Train_acc 96.75, Test_acc 33.86
2024-09-13 21:56:34,312 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.09, Train_acc 96.77, Test_acc 34.67
2024-09-13 21:56:41,889 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.25, Spatial_loss 1.17, Flat_loss 0.09, Train_acc 96.77, Test_acc 34.08
2024-09-13 21:56:51,889 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.09, Train_acc 96.81, Test_acc 34.61
2024-09-13 21:56:59,562 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.09, Train_acc 96.77, Test_acc 34.24
2024-09-13 21:57:09,948 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.25, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 96.44, Test_acc 34.06
2024-09-13 21:57:17,546 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.23, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 97.17, Test_acc 33.78
2024-09-13 21:57:27,630 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.24, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 97.00, Test_acc 34.41
2024-09-13 21:57:35,222 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.24, Spatial_loss 1.12, Flat_loss 0.09, Train_acc 96.97, Test_acc 33.89
2024-09-13 21:57:45,309 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.24, Spatial_loss 1.13, Flat_loss 0.09, Train_acc 96.82, Test_acc 33.85
2024-09-13 21:57:52,961 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.24, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 96.72, Test_acc 34.19
2024-09-13 21:58:04,787 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.24, Spatial_loss 1.14, Flat_loss 0.09, Train_acc 96.97, Test_acc 34.05
2024-09-13 21:58:13,069 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 97.13, Test_acc 34.40
2024-09-13 21:58:23,154 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.24, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 97.16, Test_acc 34.02
2024-09-13 21:58:31,663 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.24, Spatial_loss 1.11, Flat_loss 0.09, Train_acc 96.88, Test_acc 34.42
2024-09-13 21:58:42,322 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.24, Spatial_loss 1.08, Flat_loss 0.09, Train_acc 97.00, Test_acc 34.36
2024-09-13 21:58:50,185 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 97.08, Test_acc 34.34
2024-09-13 21:59:00,500 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.24, Spatial_loss 1.07, Flat_loss 0.09, Train_acc 97.07, Test_acc 34.49
2024-09-13 21:59:08,117 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.23, Spatial_loss 1.07, Flat_loss 0.09, Train_acc 97.07, Test_acc 34.22
2024-09-13 21:59:18,419 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.23, Spatial_loss 1.07, Flat_loss 0.09, Train_acc 97.30, Test_acc 34.22
2024-09-13 21:59:26,019 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.23, Spatial_loss 1.09, Flat_loss 0.09, Train_acc 97.27, Test_acc 34.44
2024-09-13 21:59:36,465 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.24, Spatial_loss 1.08, Flat_loss 0.09, Train_acc 97.16, Test_acc 34.09
2024-09-13 21:59:44,011 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.09, Train_acc 97.23, Test_acc 34.12
2024-09-13 21:59:44,012 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-13 21:59:44,012 [base.py] => Reducing exemplars...(28 per classes)
2024-09-13 22:00:01,269 [base.py] => Constructing exemplars...(28 per classes)
2024-09-13 22:00:07,915 [podnet.py] => The size of finetune dataset: 2240
2024-09-13 22:00:12,147 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.35, Spatial_loss 1.18, Flat_loss 0.06, Train_acc 92.99, Test_acc 37.65
2024-09-13 22:00:18,970 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.24, Spatial_loss 1.14, Flat_loss 0.05, Train_acc 96.70, Test_acc 37.71
2024-09-13 22:00:23,299 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.22, Spatial_loss 1.11, Flat_loss 0.05, Train_acc 97.63, Test_acc 39.11
2024-09-13 22:00:29,499 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.05, Train_acc 98.12, Test_acc 39.26
2024-09-13 22:00:36,303 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.21, Spatial_loss 1.07, Flat_loss 0.05, Train_acc 97.99, Test_acc 40.08
2024-09-13 22:00:40,682 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.05, Train_acc 98.08, Test_acc 40.39
2024-09-13 22:00:44,941 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.05, Train_acc 98.71, Test_acc 40.28
2024-09-13 22:00:50,563 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.05, Train_acc 98.75, Test_acc 40.67
2024-09-13 22:00:54,985 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.05, Train_acc 98.04, Test_acc 40.75
2024-09-13 22:00:59,395 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.05, Train_acc 98.26, Test_acc 40.90
2024-09-13 22:01:05,177 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.05, Train_acc 98.30, Test_acc 40.81
2024-09-13 22:01:09,590 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.05, Train_acc 98.57, Test_acc 40.95
2024-09-13 22:01:13,915 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.05, Train_acc 98.39, Test_acc 41.20
2024-09-13 22:01:19,691 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.05, Train_acc 98.44, Test_acc 41.34
2024-09-13 22:01:24,111 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.05, Train_acc 98.35, Test_acc 41.14
2024-09-13 22:01:28,512 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.05, Train_acc 98.75, Test_acc 41.09
2024-09-13 22:01:34,098 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.05, Train_acc 98.35, Test_acc 41.14
2024-09-13 22:01:38,577 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.05, Train_acc 98.62, Test_acc 40.99
2024-09-13 22:01:42,860 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.05, Train_acc 98.62, Test_acc 41.18
2024-09-13 22:01:48,555 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.05, Train_acc 98.93, Test_acc 41.19
2024-09-13 22:01:48,557 [base.py] => Reducing exemplars...(25 per classes)
2024-09-13 22:02:04,879 [base.py] => Constructing exemplars...(25 per classes)
2024-09-13 22:02:17,501 [podnet.py] => Exemplar size: 2000
2024-09-13 22:02:17,502 [trainer.py] => CNN: {'total': 41.19, '00-09': 53.9, '10-19': 18.2, '20-29': 36.2, '30-39': 28.7, '40-49': 47.2, '50-59': 32.1, '60-69': 49.1, '70-79': 64.1, 'old': 37.91, 'new': 64.1}
2024-09-13 22:02:17,502 [trainer.py] => NME: {'total': 38.62, '00-09': 71.7, '10-19': 17.2, '20-29': 36.3, '30-39': 26.2, '40-49': 40.7, '50-59': 25.2, '60-69': 42.3, '70-79': 49.4, 'old': 37.09, 'new': 49.4}
2024-09-13 22:02:17,502 [trainer.py] => CNN top1 curve: [90.3, 72.9, 65.23, 57.38, 53.36, 48.52, 46.0, 41.19]
2024-09-13 22:02:17,502 [trainer.py] => CNN top5 curve: [99.3, 91.95, 88.67, 83.42, 80.74, 76.17, 73.29, 69.31]
2024-09-13 22:02:17,502 [trainer.py] => NME top1 curve: [90.3, 69.15, 61.53, 52.48, 49.36, 44.37, 41.6, 38.62]
2024-09-13 22:02:17,502 [trainer.py] => NME top5 curve: [99.3, 91.35, 87.23, 82.1, 80.28, 74.73, 71.44, 68.35]

2024-09-13 22:02:17,503 [trainer.py] => All params: 514705
2024-09-13 22:02:17,503 [trainer.py] => Trainable params: 514705
2024-09-13 22:02:17,505 [podnet.py] => Learning on 80-90
2024-09-13 22:02:17,595 [podnet.py] => Adaptive factor: 3.0
2024-09-13 22:02:25,587 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 2.98, Spatial_loss 2.80, Flat_loss 0.21, Train_acc 45.46, Test_acc 19.48
2024-09-13 22:02:34,960 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 1.55, Spatial_loss 2.74, Flat_loss 0.17, Train_acc 58.39, Test_acc 22.89
2024-09-13 22:02:42,901 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 1.40, Spatial_loss 2.73, Flat_loss 0.16, Train_acc 62.31, Test_acc 25.51
2024-09-13 22:02:55,285 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 1.31, Spatial_loss 2.58, Flat_loss 0.15, Train_acc 64.97, Test_acc 25.67
2024-09-13 22:03:04,597 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 2.57, Flat_loss 0.15, Train_acc 67.49, Test_acc 25.73
2024-09-13 22:03:15,367 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 1.16, Spatial_loss 2.47, Flat_loss 0.14, Train_acc 69.46, Test_acc 28.21
2024-09-13 22:03:24,150 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 1.11, Spatial_loss 2.47, Flat_loss 0.14, Train_acc 70.09, Test_acc 27.06
2024-09-13 22:03:34,415 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 1.10, Spatial_loss 2.50, Flat_loss 0.14, Train_acc 70.24, Test_acc 23.57
2024-09-13 22:03:43,600 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 1.07, Spatial_loss 2.41, Flat_loss 0.14, Train_acc 71.97, Test_acc 26.06
2024-09-13 22:03:53,678 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 1.04, Spatial_loss 2.34, Flat_loss 0.14, Train_acc 72.17, Test_acc 27.20
2024-09-13 22:04:03,293 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 1.03, Spatial_loss 2.41, Flat_loss 0.14, Train_acc 72.86, Test_acc 25.01
2024-09-13 22:04:11,278 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.98, Spatial_loss 2.43, Flat_loss 0.14, Train_acc 74.21, Test_acc 24.99
2024-09-13 22:04:20,504 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.98, Spatial_loss 2.38, Flat_loss 0.14, Train_acc 74.16, Test_acc 27.31
2024-09-13 22:04:28,463 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.96, Spatial_loss 2.39, Flat_loss 0.14, Train_acc 75.24, Test_acc 25.68
2024-09-13 22:04:39,366 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.95, Spatial_loss 2.39, Flat_loss 0.14, Train_acc 74.96, Test_acc 27.69
2024-09-13 22:04:47,501 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.91, Spatial_loss 2.35, Flat_loss 0.14, Train_acc 76.31, Test_acc 25.68
2024-09-13 22:04:58,323 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.92, Spatial_loss 2.31, Flat_loss 0.14, Train_acc 75.67, Test_acc 25.87
2024-09-13 22:05:06,477 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.91, Spatial_loss 2.31, Flat_loss 0.14, Train_acc 75.97, Test_acc 27.40
2024-09-13 22:05:19,365 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.87, Spatial_loss 2.34, Flat_loss 0.14, Train_acc 77.43, Test_acc 26.26
2024-09-13 22:05:28,322 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.88, Spatial_loss 2.28, Flat_loss 0.14, Train_acc 77.00, Test_acc 28.36
2024-09-13 22:05:38,923 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.85, Spatial_loss 2.29, Flat_loss 0.14, Train_acc 77.86, Test_acc 26.88
2024-09-13 22:05:47,496 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.86, Spatial_loss 2.30, Flat_loss 0.14, Train_acc 77.26, Test_acc 28.13
2024-09-13 22:05:57,905 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.85, Spatial_loss 2.43, Flat_loss 0.14, Train_acc 78.73, Test_acc 25.72
2024-09-13 22:06:06,758 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.84, Spatial_loss 2.24, Flat_loss 0.14, Train_acc 78.00, Test_acc 27.06
2024-09-13 22:06:17,531 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.85, Spatial_loss 2.34, Flat_loss 0.14, Train_acc 77.96, Test_acc 27.36
2024-09-13 22:06:26,174 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.84, Spatial_loss 2.39, Flat_loss 0.14, Train_acc 78.79, Test_acc 25.73
2024-09-13 22:06:36,908 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.81, Spatial_loss 2.39, Flat_loss 0.14, Train_acc 78.71, Test_acc 25.88
2024-09-13 22:06:45,499 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.82, Spatial_loss 2.27, Flat_loss 0.14, Train_acc 78.64, Test_acc 26.48
2024-09-13 22:06:56,061 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.80, Spatial_loss 2.31, Flat_loss 0.14, Train_acc 79.76, Test_acc 26.87
2024-09-13 22:07:04,823 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.81, Spatial_loss 2.36, Flat_loss 0.14, Train_acc 79.43, Test_acc 26.37
2024-09-13 22:07:15,561 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.76, Spatial_loss 2.26, Flat_loss 0.14, Train_acc 80.79, Test_acc 28.31
2024-09-13 22:07:23,889 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.76, Spatial_loss 2.24, Flat_loss 0.14, Train_acc 79.69, Test_acc 27.12
2024-09-13 22:07:34,909 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.74, Spatial_loss 2.25, Flat_loss 0.14, Train_acc 80.89, Test_acc 26.98
2024-09-13 22:07:46,287 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.75, Spatial_loss 2.27, Flat_loss 0.14, Train_acc 80.66, Test_acc 24.23
2024-09-13 22:07:54,481 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.74, Spatial_loss 2.30, Flat_loss 0.14, Train_acc 81.13, Test_acc 28.87
2024-09-13 22:08:03,691 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.74, Spatial_loss 2.24, Flat_loss 0.14, Train_acc 80.49, Test_acc 27.93
2024-09-13 22:08:11,659 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.75, Spatial_loss 2.38, Flat_loss 0.15, Train_acc 80.71, Test_acc 25.47
2024-09-13 22:08:22,433 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.72, Spatial_loss 2.21, Flat_loss 0.14, Train_acc 81.79, Test_acc 26.72
2024-09-13 22:08:30,537 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.72, Spatial_loss 2.26, Flat_loss 0.14, Train_acc 82.41, Test_acc 27.69
2024-09-13 22:08:41,254 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.72, Spatial_loss 2.18, Flat_loss 0.14, Train_acc 81.69, Test_acc 27.21
2024-09-13 22:08:49,404 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.73, Spatial_loss 2.22, Flat_loss 0.14, Train_acc 81.21, Test_acc 27.07
2024-09-13 22:09:00,116 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.69, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 82.43, Test_acc 28.13
2024-09-13 22:09:08,343 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.71, Spatial_loss 2.25, Flat_loss 0.14, Train_acc 81.93, Test_acc 26.98
2024-09-13 22:09:19,105 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.69, Spatial_loss 2.16, Flat_loss 0.14, Train_acc 82.34, Test_acc 26.43
2024-09-13 22:09:27,144 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.67, Spatial_loss 2.20, Flat_loss 0.14, Train_acc 83.17, Test_acc 28.97
2024-09-13 22:09:38,077 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.68, Spatial_loss 2.21, Flat_loss 0.14, Train_acc 82.67, Test_acc 27.76
2024-09-13 22:09:46,181 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.68, Spatial_loss 2.20, Flat_loss 0.14, Train_acc 82.83, Test_acc 29.09
2024-09-13 22:09:57,130 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.68, Spatial_loss 2.19, Flat_loss 0.14, Train_acc 82.77, Test_acc 28.23
2024-09-13 22:10:07,613 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.64, Spatial_loss 2.10, Flat_loss 0.14, Train_acc 83.80, Test_acc 29.30
2024-09-13 22:10:18,149 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.64, Spatial_loss 2.11, Flat_loss 0.14, Train_acc 84.07, Test_acc 29.66
2024-09-13 22:10:27,016 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.65, Spatial_loss 2.12, Flat_loss 0.14, Train_acc 84.06, Test_acc 26.71
2024-09-13 22:10:37,890 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.67, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 83.16, Test_acc 27.43
2024-09-13 22:10:46,787 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.66, Spatial_loss 2.14, Flat_loss 0.14, Train_acc 83.30, Test_acc 29.28
2024-09-13 22:10:57,517 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.64, Spatial_loss 2.15, Flat_loss 0.14, Train_acc 84.06, Test_acc 25.76
2024-09-13 22:11:06,270 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.61, Spatial_loss 2.07, Flat_loss 0.14, Train_acc 84.70, Test_acc 29.31
2024-09-13 22:11:16,898 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.59, Spatial_loss 2.13, Flat_loss 0.14, Train_acc 85.26, Test_acc 27.38
2024-09-13 22:11:25,468 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.61, Spatial_loss 2.12, Flat_loss 0.14, Train_acc 84.80, Test_acc 27.32
2024-09-13 22:11:36,107 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.59, Spatial_loss 2.12, Flat_loss 0.14, Train_acc 85.66, Test_acc 26.93
2024-09-13 22:11:45,010 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.60, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 85.20, Test_acc 27.99
2024-09-13 22:11:54,997 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.57, Spatial_loss 2.11, Flat_loss 0.14, Train_acc 86.43, Test_acc 27.98
2024-09-13 22:12:04,559 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.57, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 85.97, Test_acc 30.17
2024-09-13 22:12:12,709 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.58, Spatial_loss 2.04, Flat_loss 0.14, Train_acc 85.86, Test_acc 28.46
2024-09-13 22:12:21,979 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.57, Spatial_loss 2.05, Flat_loss 0.13, Train_acc 86.23, Test_acc 29.21
2024-09-13 22:12:34,740 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.55, Spatial_loss 2.08, Flat_loss 0.14, Train_acc 86.76, Test_acc 28.62
2024-09-13 22:12:42,910 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.55, Spatial_loss 2.06, Flat_loss 0.13, Train_acc 86.79, Test_acc 28.81
2024-09-13 22:12:52,320 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.56, Spatial_loss 2.02, Flat_loss 0.13, Train_acc 86.14, Test_acc 29.44
2024-09-13 22:13:00,534 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.54, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 87.31, Test_acc 29.11
2024-09-13 22:13:11,622 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.55, Spatial_loss 1.97, Flat_loss 0.13, Train_acc 86.73, Test_acc 29.52
2024-09-13 22:13:19,740 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.53, Spatial_loss 2.03, Flat_loss 0.13, Train_acc 87.66, Test_acc 27.56
2024-09-13 22:13:30,707 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.53, Spatial_loss 2.01, Flat_loss 0.13, Train_acc 87.26, Test_acc 29.82
2024-09-13 22:13:38,787 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.53, Spatial_loss 2.03, Flat_loss 0.13, Train_acc 87.46, Test_acc 28.71
2024-09-13 22:13:49,672 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.50, Spatial_loss 1.93, Flat_loss 0.13, Train_acc 88.34, Test_acc 29.04
2024-09-13 22:13:57,835 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.51, Spatial_loss 1.98, Flat_loss 0.13, Train_acc 88.14, Test_acc 28.34
2024-09-13 22:14:08,754 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.50, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 88.69, Test_acc 30.58
2024-09-13 22:14:17,033 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.50, Spatial_loss 1.95, Flat_loss 0.13, Train_acc 88.50, Test_acc 30.70
2024-09-13 22:14:27,919 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.50, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 88.21, Test_acc 27.33
2024-09-13 22:14:36,235 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.49, Spatial_loss 1.94, Flat_loss 0.13, Train_acc 88.69, Test_acc 29.53
2024-09-13 22:14:48,835 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.48, Spatial_loss 1.89, Flat_loss 0.13, Train_acc 88.66, Test_acc 29.17
2024-09-13 22:14:57,766 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.47, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 89.36, Test_acc 30.90
2024-09-13 22:15:08,706 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.48, Spatial_loss 1.92, Flat_loss 0.13, Train_acc 88.64, Test_acc 26.93
2024-09-13 22:15:17,623 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.47, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 89.54, Test_acc 30.38
2024-09-13 22:15:28,437 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.46, Spatial_loss 1.86, Flat_loss 0.13, Train_acc 89.60, Test_acc 29.42
2024-09-13 22:15:36,954 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.45, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 89.96, Test_acc 28.18
2024-09-13 22:15:47,956 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.45, Spatial_loss 1.87, Flat_loss 0.12, Train_acc 90.29, Test_acc 29.13
2024-09-13 22:15:56,051 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.43, Spatial_loss 1.82, Flat_loss 0.12, Train_acc 90.37, Test_acc 30.68
2024-09-13 22:16:06,996 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.43, Spatial_loss 1.88, Flat_loss 0.13, Train_acc 90.51, Test_acc 30.09
2024-09-13 22:16:15,401 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.43, Spatial_loss 1.82, Flat_loss 0.12, Train_acc 90.76, Test_acc 31.30
2024-09-13 22:16:26,335 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.42, Spatial_loss 1.79, Flat_loss 0.12, Train_acc 90.73, Test_acc 29.36
2024-09-13 22:16:34,356 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.41, Spatial_loss 1.76, Flat_loss 0.12, Train_acc 91.00, Test_acc 31.14
2024-09-13 22:16:45,362 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.42, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 91.30, Test_acc 27.70
2024-09-13 22:16:53,590 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.40, Spatial_loss 1.81, Flat_loss 0.12, Train_acc 91.97, Test_acc 30.34
2024-09-13 22:17:04,936 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.39, Spatial_loss 1.77, Flat_loss 0.12, Train_acc 92.23, Test_acc 28.92
2024-09-13 22:17:17,855 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.40, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 91.81, Test_acc 29.70
2024-09-13 22:17:25,918 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.39, Spatial_loss 1.73, Flat_loss 0.12, Train_acc 92.43, Test_acc 29.57
2024-09-13 22:17:35,176 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.36, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 93.20, Test_acc 29.57
2024-09-13 22:17:43,199 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.37, Spatial_loss 1.74, Flat_loss 0.12, Train_acc 92.41, Test_acc 28.01
2024-09-13 22:17:54,252 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.36, Spatial_loss 1.72, Flat_loss 0.12, Train_acc 92.99, Test_acc 30.96
2024-09-13 22:18:02,540 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.35, Spatial_loss 1.70, Flat_loss 0.12, Train_acc 93.27, Test_acc 30.08
2024-09-13 22:18:13,423 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.34, Spatial_loss 1.67, Flat_loss 0.12, Train_acc 93.70, Test_acc 32.07
2024-09-13 22:18:21,771 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.34, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 93.70, Test_acc 30.14
2024-09-13 22:18:32,485 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.35, Spatial_loss 1.71, Flat_loss 0.12, Train_acc 93.13, Test_acc 30.41
2024-09-13 22:18:40,644 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.35, Spatial_loss 1.66, Flat_loss 0.12, Train_acc 93.37, Test_acc 28.52
2024-09-13 22:18:51,402 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.34, Spatial_loss 1.62, Flat_loss 0.11, Train_acc 93.69, Test_acc 30.96
2024-09-13 22:18:59,347 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.33, Spatial_loss 1.67, Flat_loss 0.11, Train_acc 93.90, Test_acc 29.77
2024-09-13 22:19:09,928 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.31, Spatial_loss 1.60, Flat_loss 0.11, Train_acc 94.34, Test_acc 30.42
2024-09-13 22:19:18,158 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.33, Spatial_loss 1.64, Flat_loss 0.11, Train_acc 93.93, Test_acc 30.37
2024-09-13 22:19:30,977 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.32, Spatial_loss 1.57, Flat_loss 0.11, Train_acc 94.24, Test_acc 30.31
2024-09-13 22:19:40,082 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.31, Spatial_loss 1.53, Flat_loss 0.11, Train_acc 94.49, Test_acc 30.23
2024-09-13 22:19:50,610 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.31, Spatial_loss 1.56, Flat_loss 0.11, Train_acc 94.61, Test_acc 31.01
2024-09-13 22:19:59,355 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.31, Spatial_loss 1.56, Flat_loss 0.11, Train_acc 94.47, Test_acc 31.71
2024-09-13 22:20:10,221 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.30, Spatial_loss 1.60, Flat_loss 0.11, Train_acc 95.40, Test_acc 31.44
2024-09-13 22:20:18,950 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.30, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 95.11, Test_acc 30.60
2024-09-13 22:20:29,611 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.29, Spatial_loss 1.51, Flat_loss 0.11, Train_acc 95.41, Test_acc 30.03
2024-09-13 22:20:38,142 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.29, Spatial_loss 1.50, Flat_loss 0.11, Train_acc 95.56, Test_acc 31.50
2024-09-13 22:20:49,008 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.28, Spatial_loss 1.49, Flat_loss 0.11, Train_acc 96.07, Test_acc 30.23
2024-09-13 22:20:57,616 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.29, Spatial_loss 1.54, Flat_loss 0.11, Train_acc 95.31, Test_acc 30.98
